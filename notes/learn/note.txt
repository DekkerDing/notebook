热点Key
    热点key的解决方案之一：避免带宽或者传输影响本地缓存热点key数据对于每次读请求将首先检查key是否存在于本地缓存中
    如果存在则直接返回如果不存在再去访问分布式缓存的机器
    缓存中的某些Key对应的value存储在集群中一台机器使得所有流量涌向同一机器成为系统的瓶颈
    无法通过增加机器容量来解决

配置
    bind 绑定指定ip访问
    daemonize 是否后台运行
    port 端口号
    requirepass 密码配置
    dbfilename 配置redis持久化文件名称
    dir 配置redis持久化文件存储地址
    save 配置redis持久化机制
        #持久化策略，10秒内有个1个key改动，执行快照
        save 1 0
    rdbcompression yes 导出rdb数据库文件压缩字符串和对象，默认是yes，会浪费cPu但是节省空间
    rdbchecksum yes 导入时是否检查
    appendonly yes  开启 AOF 默认不开启

KEY命名
    不要过长本身key也占据空间
    冒号分割不要有特殊字符(空格-引|号-转义符)
    业务名：表名：ID
        product-service:produdct:1
        user:sign:1

数据结构
    通用
        exists 判断key是否存在
        del 删除key
        type 判断key类型
        ttl 查看key存活时间
            XX：具有时效性的数据
            -1：永久有效的数据
            -2：已经过期的数据 或 被删除的数据 或 未定义的数据
    String
        存储字符串类型的key-value
        值的长度不能超过512MB
        key命名规范，不要过长，冒号分割
        业务名：表名：ID
        应用场景
            验证码
            计数器、发号器
            订单重复提交令牌
            热点商品卡片（序列化json对象存储）
            分布式锁
        set/get
            设置和获取key-value
        mget/mset
            批量设置或获取多个key的值
            MGET key[key ...]
            MSET key value[key value...]
        incr
            incr对key对应的值进行加1操作并返回新的值
            incr key
        incrby
            将key对应的数字加increment
            如果key不存在操作之前key就会被置为0
            incrby key increment
        setex
            设置key对应字符串value并且设置key在给定的
            seconds
            时间之后超时过期
            原子操作
            SETEX key seconds value
        setnx
            将key设置值为value
            如果key不存在等同SET命令
            当key存在时什么也不做是
            set if not exists 的简写
            SETNX key value
        getset
            设置key的值并返回key旧的值
            GETSET KEY_NAME VALUE
    List
        字符串列表，按照插入顺序排序
        双向链表，插入删除时间复杂度 o（1）快，查找为 o（n）慢
        通常添加一个元素到列表的头部（左边）或者尾部（右边）
        存储的都是string字符串类型
        支持分页操作，高并发项目中，第一页数据都是来源list，第二页和更多信息则是通过数据库加载
        一个列表最多可以包含232－1个元素（4294967295，每个列表不超过40亿个元素）
        应用场景
            简单队列
            最新评论列表
            非实时排行榜：定时计算榜单，如手机日销榜单
        lpush
            将一个或多个值插入到列表头部
            LPUSH key value1 [value2]
            移除并获取列表最后一个元素
        llen
            获取列表长度
            LLEN key
        lrange
            获取key对应的list的指定下标范围的元素
            其中0表示列表的第一个元素
            1表示列表的第二个元素
            -1表示获取所有元素（lrange key 0 -1）
            LRANGE key start stop
        rpop
            移除并获取列表最后一个元素
            RPOP key
        rpush
            在key对应的list的尾部添加一个元素
            RPUSH key value1[value2]
        lpop
            从key对应的list的尾部删除一个元素并返回该元素
            LPOP key
        brpop
            移出并获取列表的最后一个元素
            如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止
            BRPOP LIST1 LIST2..LISTN TIMEOUT
        lrem
            移除元素，可以指定移除个数 (类似于去重)
            LREM KEY COUNT VALUE
    Hash
        key：[{field：value}]
        是一个string类型的field和value的映射表 hash特别适合用于存储对象
        每个hash可以存储232-1键值对（40多亿）
        应用场景
            购物车
            用户个人信息
            商品详情
        hset
            设置key指定的哈希集中指定字段的值
            HSET key field value
        hget
            返回key指定的哈希集中该字段所关联的值
            HGET key field
        hgetall
            返回key指定的哈希集中所有的字段和值
            HGETALL key
        hdel
            从key指定的哈希集中移除指定的域
            HDEL key field [field ...]
        hexists
            返回hash里面field是否存在
            HEXISTS key field
        hincrby
            增加key指定的哈希集中指定字段的数值，如果是-1则是递减
            HINCRBY key field increment
        hmset
            设置key指定的哈希集中指定字段的值
            HMSET key field value[field value...]
        hmget
            设置key指定的哈希集中指定字段的值
            HMGET key field [field ...]
    Set
        Set集合
        将一个或多个成员元素加入到集合中，已经存在于集合的成员元素将被忽略
        集合是通过哈希表实现的
        应用场景
            去重
            社交应用关注、粉丝、共同好友
            统计网站的PV、UV、IP
            大数据里面的用户画像标签集合
        sadd
            添加一个或多个指定的member元素到集合的key中
            指定一个或者多个元素member
            如果已经在集合key中存在则忽略
            SADD key member [member...]
        scard
            返回集合存储的key的基数（集合元素的数量）
            SCARD key
        sdiff
            返回的集合元素是第一个key的集合与后面所有key的集合的差集
            SDIFF key [key ...]
        sinter
            返回指定所有的集合的成员的交集
            SINTER key[key ...]
        sismember
            返回成员member是否是存储的集合key的成员
            SISMEMBER key member
        srem
            在key集合中移除指定的元素.如果指定的元素不是key集合中的元素则忽略
            SREM key member[member..]
        sunion
            返回给定的多个集合的并集中的所有成员
            SUNION key[key ...]
        smembers
            返回key集合所有的元素
            SMEMBERS key
    Sorted Set
        用于将一个或多个成员元素及其分数值加入到有序集当中
        如果某个成员已经是有序集的成员，那么更新这个成员的分数值，分数值可以是整数值或双精度浮点数。
        有序集合可以看做是在Set集合的的基础上为集合中的每个元素维护了一个顺序值：score
        它允许集合中的元素可以按照score进行排序
        底层使用到了Ziplist压缩列表和“跳跃表”两种存储结构
        如果重复添加相同的数据，score值将被反复覆盖，保留最后一次修改的结果
        应用场景
            实时排行榜：商品热销榜、体育类应用热门球队、积分榜
            优先级任务、队列
            朋友圈文章点赞-取消，逻辑：用户只能点赞或取消，统计一篇文章被点赞了多少次，可以直接取里面有多少个成员
        zadd
            向有序集合添加一个或多个成员，或者更新已存在成员的分数
            ZADD key score1 member1 [score2 member2]
        zcard
            获取有序集合的成员数
            ZCARD key
        zcount
            计算在有序集合中指定区间分数的成员数
            ZCOUNT key min max
        zincrby
            有序集合中对指定成员的分数加上增量increment
            ZINCRBY key increment member
        zrange
            通过索引区间返回有序集合指定区间内的成员，成员的位置按分数值递增（从小到大）来排序
            ZRANGE key start stop [WITHSCORES]
        zrevrange
            通过索引区间返回有序集合指定区间内的成员，成员的位置按分数值递增（从大到小）来排序
            ZREVRANGE key Start stop [WITHSCORES]
        zrevrank
            返回有序集合中指定成员的排名，有序集成员按分数值递减（从大到小）排序
            ZREVRANK key member
        zrank
            返回有序集key中成员member的排名。其中有序集成员按score值递增（从小到大）顺序排列
            ZRANK key member
        zrem
            移除有序集合中的一个或多个成员
            ZREM key member [member...]
        zscore
            返回有序集中，成员的分数值
            ZSCORE key member
跳表
    SkipList（跳表）首先是链表，但与传统链表相比有几点差异：
        元素按照升序排列存储
        节点可能包含多个指针，指针跨度不同。
SortedSet
    SortedSet是有序集合
    底层的存储的每个数据都包含element和score两个值
    score是得分
    element则是字符串值
    SortedSet会根据每个element的score值排序形成有序集合
    加分项：
        因为SortedSet底层需要用到两种数据结构
        对内存占用比较高。
        因此Redis底层会对SortedSet中的元素大小做判断。
        如果元素大小小于128且每个元素都小于64字节，SortedSet底层会采用ZipList
        也就是压缩列表来代替HashTable和SkipList

Java 客户端
    jedis
        Jedis是直连模式
        在多个线程间共享一个Jedis实例时是线程不安全的需要使用连接池其API提供了比较全面的Redis命令的支持
        相比于其他Redis封装框架更加原生
        Jedis中的方法调用是比较底层的暴露的Redis的API
        Java方法基本和Redis的API保持着一致使用阻塞的I/o方法调用同步
        程序流需要等到socket处理完I/o才能执行
        不支持异步操作
    lettuce
        高级Redis客户端，用于线程安全同步，异步和响应使用
        基于Netty的的事件驱动，可以在多个线程间并发访问，通过异步的方式可以更好的利用系统资源

RedisTemplate
    ValueOperations：简单K-V操作
    SetOperations：set类型数据操作
    ZSetOperations：zset类型数据操作
    HashOperations：针对map类型的数据操作
    ListOerations：list类型的数据操作

分布式锁
    排它性
        在分布式应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行
    容错性
        分布式锁一定能得到释放，比如客户端奔溃或者网络中断
    问题
        多个命令之间不是原子性操作
            如setnx和expire之间
            如果 setnx成功但是expire失败
            且宕机了则这个资源就是死锁
            redisTemplate.opsForValue().setIfAbsent("seckill_1","success",30,TimeUnit.MILLISECONDS)
        业务超时 存在其他线程勿删
            可以在de1释放锁之前做一个判断
            验证当前的锁是不是自己加的锁
            拿value应该是存当前线程的标识或者uuid

SpringCache
    @Cacheable
        标记在一个方法上，也可以标记在一个类上
        缓存标注对象的返回结果，标注在方法上缓存该方法的返回值，标注在类上缓存该类所有的方法返回值
        value缓存名称，可以有多个
        key缓存的key规则，可以用springEL表达式，默认是方法参数组合
        condition缓存条件，使用springEL编写，返回true才缓存
        // 对象
        @Cacheable(value ={"product"}，key="#root.methodName")
        // 分页
        @Cacheable(value = {"product_page"},key="#root.methodName + #page+'_'+#size")

        methodName当前被调用的方法名
        root.methodname
        args当前被调用的方法的参数列表
        root.args[0]
        result方法执行后的返回值
    @CachePut
        根据方法的请求参数对其结果进行缓存，每次都会触发真实方法的调用
        @CachePut(value ={"product"},key="#productDo.id")
    @CacheEvict
        从缓存中移除相应数据，触发缓存删除的操作
        beforelnvocation= true/false
            false 缓存的清除是否在方法之前执行，默认代表缓存清除操作是在方法执行之后执行 如果出现异常缓存就不会清除
            true 代表清除缓存操作是在方法运行之前执行，无论方法是否出现异常，缓存都清除
        @CacheEvict(value ={"product"},key="#root.args[0]"，cacheManager="customCacheManager")
    @Caching
        组合多个Cache注解使用 允许在同一方法上使用多个嵌套的@Cacheable、@CachePut和@CacheEvict注释

缓存击穿 (某个热点key缓存失效了)
    缓存中没有但数据库中有的数据
    假如是热点数据那key在缓存过期的一刻同时有大量的请求
    这些请求都会击穿到DB造成瞬时DB请求量大压力增大
    和缓存雪崩的区别在于这里针对某一key缓存 后者则是很多key
    预防
        设置热点数据不过期
        定时任务定时更新缓存
        设置互斥锁
        SpringCache解决方案
            缓存的同步sync
            sync可以指示底层将缓存锁住 使只有一个线程可以进入计算而其他线程堵塞直到返回结果更新到缓存中
            @Cacheable(value ={"product"},key="#root.args[o]"，cacheManager="customCacheManager" sync=true)
缓存雪崩(多个热点key都过期）
    大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩
    预防
        存数据的过期时间设置随机，防止同一时间大量数据过期现象发生
        设置热点数据永远不过期，定时任务定时更新
        SpringCache解决方案
            比如CacheManager配置多个过期时间维度
缓存穿透（查询不存在数据）
    查询一个不存在的数据，由于缓存是不命中的，并且出于容错考虑，如发起为id为"-1"不存在的数据
    如果从存储层查不到数据则不写入缓存这将导致这个不存在的数据每次请求都要到存储层去查询
    失去了缓存的意义
    存在大量查询不存在的数据可能DB就挂掉了
    这也是黑客利用不存在的key频繁攻击应用的一种方式
    预防
        接口层增加校验，数据合理性校验
        缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，设置短点的过期时间，防止同个key被一直攻击
        SpringCache解决方案
            空结果也缓存，默认不配置condition或者unless就行
缓存预热
    请求数量较高
    主从之间数据吞吐量较大，数据同步操作频度较高
    方案
        日常例行统计数据访问记录统计访问频度较高的热点数据
            利用LRU数据删除策略构建数据留存队列
            storm与kafka配合

热 Key
    热key是指那些在极短的时间内访问频次非常高的key
        对应节点的网卡带宽被打满，出现丢包重传，请求波动耗时大幅上升
        请求过多，热点key引l起redis节点数据倾斜，缓存服务被打垮
        大量的请求穿透到DB，DB扛不住岩机
        热点key的出现可能会对系统的稳定性和可用性造成巨大的影响
        在日常的工作中
        我们需要尽可能避免这种情况的出现
        比如在设计和编码阶段避免引人全局性热key，或者在设计时考虑热key出现时的应对方案。
    redis在4.0版本之后添加了hotkeys查找特性[1]
    可以直接利用redis-cli--hotkeys获取当前keyspace的热点key。
    该方案无需二次开发
    能够直接利用现成的工具
    但由于需要扫描整个keyspace，实时性上比较差，另外扫描耗时与key的数量正相关
    如果key的数量比较多，耗时可能会非常长。

Redis 大Key
    在Redis中，大key指的是key对应的value值所占的内存空间比较大。
    value是string类型，大小控制在10kb以内
    value是hash、list、set、zset等集合类型，元素个数不要超过5000（或则1万、几万)
    主要是根据value的大小和元素个数来确定，业务也可以根据自已的场景确定标准。
    很多朋友肯定在想redis的key能有多大呀？
    这里就有个误区了，所谓的大key问题是某个key对应的value比较大
    所以本质上是大value问题。
    key往往是开发过程中可以自行设置
    可以控制大小
    value往往不受程序控制跟业务场景有关系
    因此可能导致value很大
    总结
        大key的产生往往是业务方设计不合理，没有预见vaule的动态增长问题
        一直往value塞数据，没有删除及过期机制，迟早要爆炸
        数据没有合理做分片，将大key变成以一个个小key
        第一，是不是有必要把所有字段都缓存
        第二，有没有相关联的数据，关联数据分开存储
    出来的现象
        客户端超时阻塞
        由于Redis单线程的特性，操作bigkey的通常比较耗时
        也就意味着阻塞Redis可能性越大，这样会造成客户端阻塞或者引起故障切换
        会出现各种redis 慢查询中。
        内存空间不均匀
        集群模式在slot分片均匀情况下，会出现数据和查询倾斜情况
        部分有大key的Redis节点占用内存多
        QPS高。
        引发网络阻塞
        每次获取大key产生的网络流量较大
        如果一个key的大小为1MB，每秒访问量为1000
        那么每秒会产生1000MB的流量。
        这对于普通千兆网卡的服务器来说是灾难性的
        阻塞工作线程
        执行大key删除时，在低版本redis中可能阻塞线程。
    处理/删除
        如果对这类大key直接使用del命令进行删除
        会导致长时间阻塞
        甚至崩溃因为del命令在删除集合类型数据时
        时间复杂度为O(M)，M是集合中元素的个数。
        Redis是单线程的，单个命令执行时间过长就会阻塞其他命令，容易引起雪崩。那我们怎么解决呢？
            主动删除大 key
            分批次渐进式删除
            一般来说，对于strint数据类型使用del命令不会产生阻塞。
            其它数据类型分批删除，通过 scan命令遍历大key，每次取得少部分元素进行删除，然后再获取和删除下一批元素。
            对Hash，SortedSet，List，Set分别处理，思路相同，先对key改名进行逻辑删除，使客户端无法使用原key，然后使用批量小步删除。
            删除大Hash
                key改名，相当于逻辑上把这个key删除了，任何redis命令都访问不到这个key了
                小步多批次的删除
                redis.HDEL(newkey,hash_keys)
            删除大List
                redis.LTRIM（newkey,0,-99)
            删除大Set
                redis.SREM(newkey,members)
            删除大Sorted Set
                redis.ZREMRANGEBYRANK(newkey,0，99)
        采用unlink+bigkey异步非阻塞删除。这个命令是在redis4.0+提供的代替del命令，
        被动删除大key
            被动删除是指利用redis自身的key清除策略，配置lazyfree惰性删除。但是参数默认是关闭的
                lazyfree-lazy-expire on #过期情性删除
                lazyfree-lazy-eviction on  #超过最大内存情性删除
                lazyfree-lazy-server-del on #服务端被动惰性删除
    设计
        从业务角度评估，value中只存储有用的字段，尽量去掉无用的字段。
        可以考虑在应用层先对value进行压缩，比如采用LZ4/Snappy之类的压缩算法
        配合redis客户端序列化配置，可以无侵人完成value的压缩。
        value设计的时候越小越好，关联的数据分不同的key进行存储。
        大key分拆成几个key-value
        使用multiGet获取值，这样分拆的意义在于分拆单次操作的压力，将操作压力平摊到多个redis实例中
        降低对单个redis的IO影响
订阅与发布

事务
    Redis 事务的本质是一组命令的集合
    事务支持一次执行多个命令，一个事务中所有命令都会被序列化
    在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中
    Redis当中不存在隔离级别的概念
    没有原子性的概念
    执行失败的命令对其他的命令没有影响
    multi：标记一个事务块的开始（queued）类似于关系型数据库的start
    exec：执行所有事务块的命令 类似于关系型数据库当中commit（一旦执行exec后，之前加的监控锁都会被取消掉
    discard：取消事务，放弃事务块中的所有命令 类似于关系型数据库当中rollback
    watch key1 key2...：监视一或多个key，如果在事务执行之前，被监视的key被其他命令改动，则事务被打断（类似乐观锁）
    unwatch：取消watch对所有key的监控

持久化
    RDB：RedisDataBase，在指定的时间间隔内将内存中的数据集快照写入磁盘，
    实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储
    AOF：AppendOnlyFile，以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录
    AOF文件比RDB更新频率高，优先使用AOF还原数据，AOF比RDB更安全也更大，RDB性能比AOF好，如果两个都配了优先加载AOF。
    RDB
        在指定的时间间隔内将内存中的数据集快照写入磁盘
        默认的文件名为dump.rdb
        save
            会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成为止
        bgsave
            fork创建子进程，RDB持久化过程由子进程负责，会在后台异步进行快照操作，快照同时还可以响应客户端请求
        自动化
            配置文件来完成 配置触发Redis的RDB持久化条件
            比如"savemn" 表示m秒内数据集存在n次修改时 自动触发bgsave
        主从架构
            从服务器同步数据的时候 会发送sync执行同步操作 master主服务器就会执行bgsave
        优点
            RDB文件紧凑
            全量备份
            适合用于进行备份和灾难恢复
            在恢复大数据集时的速度比AOF的恢复速度要快
            生成的是一个紧凑压缩的二进制文件
            RDB最大限度地提高了Redis的性能，父进程不需要参与磁盘I/O
            RDB文件紧凑，全量备份，适合用于进行备份和灾难恢复
            在恢复大数据集时的速度比AOF的恢复速度要快
        缺点
            每次快照是一次全量备份
            fork子进程进行后台操作子进程存在开销
            在快照持久化期间修改的数据不会被保存
            可能丢失数据
            如果您需要在Redis停止工作时（例如断电后）
            将数据丢失的可能性降至最低则RDB并不好
            RDB经常需要fork（）才能使用子进程持久存储在磁盘上
            如果数据集很大，Fork（）可能会非常耗时
    AOF
        appendonlyfile，追加文件的方式，文件容易被人读懂
        以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令达到恢复数据的目的
        写入过程岩机，也不影响之前的数据，可以通过redis-check-aof检查修复问题
        AOF文件名通过appendfilename配置设置，默认文件名是appendonly.aof
        存储路径同RDB持久化方式一致，使用dir配置
        Redis每次写入命令会追加到aof_buf（缓冲区）
        AOF缓冲区根据对应的策略向硬盘做同步操作
        高频AOF会带来影响，特别是每次刷盘
        appendfsync always
            每次有数据修改发生时都会写入AOF文件，消耗性能多
        appendfsync everysec
            每秒钟同步一次，该策略为AOF的缺省策略。
        appendfsync no
            不主从同步，由操作系统自动调度刷磁盘，性能是最好的，但是最不安全
        rewrite重写
            AOF文件越来越大，需要定期对AOF文件进行重写达到压缩
            旧的AOF文件含有无效命令会被忽略，保留最新的数据命令
            多条写命令可以合并为一个
            AOF重写降低了文件占用空间
            更小的AOF文件可以更快地被Redis加载
            重写触发
                直接调用bgrewriteaof命令
                auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数
                auto-aof-rewrite-min-size
                    表示运行AOF重写时文件最小体积，默认为64MB
                    AOF文件最小重写大小只有当AOF文件大小大于该值时候才可能重写
                    6.x默认配置64mb
                auto-aof-rewrite-percentage
                    代表当前AOF文件空间和上一次重写后AOF文件空间（aof_base_size）的比值
                    当前AOF文件大小和最后一次重写后的大小之间的比率等于或者等于指定的增长百分比
                    如100代表当前AOF文件是上次写的两倍
                    时候才重写。
            aof-load-truncated yes
                加载aof时如果有错如何处理
                yes表示如果aof尾部文件出问题，写log记录并继续执行。no表示提示写入等待修复后写入
        优点
            数据更加安全
            当RedisAOF文件太大时
            Redis能够在后台自动重写AOF
            AOF以易于理解和解析的格式一个接一个地包含所有操作的日志
        缺点
            AOF文件通常比同一数据集的等效RDB文件大
            根据确切的fsync策略
            AOF可能比RDB慢
    AOF+RDB混合模式
        RDB持久化以指定的时间间隔执行数据集的时间点快照。
        AOF持久化记录服务器接收的每个写入操作
        将在服务器启动时再次读取重建原始数据集
        使用与Redis协议本身相同的格式以仅追加方式记录命令
        当文件太大时Redis能够重写
        推荐方案
            RDB持久化与AOF持久化一起使用
            如果Redis中的数据并不是特别敏感或者可以通过其它方式重写生成数据
            集群中可以关闭AOF持久化靠集群的备份方式保证可用性
            自己制定策略定期检查Redis的情况，然后可以手动触发备份、重写数据；
            采用集群和主从同步
        Redis4.0后开始的rewrite支持混合模式
            就是rdb和aof一起用
            直接将rdb持久化的方式来操作将二进制内容覆盖到aof文件中，rdb是二进制，所以很小
            有写入的话还是继续append追加到文件原始命令，等下次文件过大的时候再次rewrite
            默认是开启状态
            优点
                混合持久化结合了RDB持久化和AOF持久化的优点
                采取了rdb的文件小易于灾难恢复同时结合AOF
                增量的数据以AOF方式保存了数据更少的丢失
            缺点
                前部分是RDB格式，是二进制，所以阅读性较差
            数据恢复
                先看是否存在aof文件
                若存在则先按照aof文件恢复
                aof比rdb全且aof文件也rewrite成rdb二进制格式若aof不存在
                则才会查找rdb是否存在
        选择
            当我们对数据的要求没那么高，允许少部分数据丢失：优先采用RDB
            Redis启动的时候会优先加载aof文件，aof文件保存的数据更加的完整。

过期删除
    Redis如何淘汰过期的keys： set name xdclass 3600
    Redis服务器实际使用的是惰性删除和定期删除两种策略：
    通过配合使用这两种删除策略
    服务器可以很好地在合理使用CPU时间和避免浪费内存空间之间取得平衡
    定期删除
        隔一段时间，就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除
        定期删除可能会导致很多过期key到了时间并没有被删除掉，那咋整呢，所以就是惰性删除
        周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度
        特点1：CPU性能占用设置有峰值，检测频度可自定义设置
        特点2：内存压力不是很大，长期占用内存的冷数据会被持续清理
        总结：周期性抽查存储空间 (随机抽查，重点抽查)
    惰性删除
        数据到达过期时间，不做处理。等下次访问该数据时
        如果未过期，返回数据 发现已过期，删除，返回不存在
        概念：当一些客户端尝试访问它时，key会被发现并主动的过期
        放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键
        优点
            节约CPU性能，发现必须删除的时候才删除
        缺点
            内存压力很大，出现长期占用内存的数据
        总结：用存储空间换取处理器性能 (拿空间换时间)
    定时删除
        创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作
        总结：用处理器性能换取存储空间 (拿时间换空间)
        优点
            节约内存，到时就删除，快速释放掉不必要的内存占用
        缺点
            CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量
    1． 定时删除 节约内存，无占用 不分时段占用CPU资源，频率高
    2． 惰性删除 内存占用严重 延时执行，CPU利用率高
    3． 定期删除 内存定期随机清理 每秒花费固定的CPU资源维护内存
    如果定期删除漏掉了很多过期key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？
    如果大量过期key堆积在内存里，导致redis内存块耗尽了，就需要走内存淘汰机制

内存淘汰机制
    内存不足时-Redis的Key内存淘汰策略
    redis在占用的内存超过指定的maxmemory之后
    maxmemory-samples count
        每次选取待删除数据的个数，采用随机获取数据的方式作为待检测删除数据
    通过maxmemory_policy确定redis是否释放内存以及如何释放内存
    策略
        volatile-lru(least recently used) 检测易失数据 长时间不活跃数据
            最近最少使用算法，从设置了过期时间的键中选择空转时间最长的键值对清除掉
        volatile-lfu(least frequently used) 检测易失数据 使用次数最少的
            最近最不经常使用算法，从设置了过期时间的键中选择某段时间之内使用频次最小的键值对清除掉
        volatile-ttl 检测易失数据
            从设置了过期时间的键中选择过期时间最早的键值对清除；
        volatile-random 检测易失数据
            从设置了过期时间的键中，随机选择键进行清除；
        allkeys-lru 检测全库数据
            最近最少使用算法，从所有的键中选择空转时间最长的键值对清除；
        allkeys-lfu 检测全库数据
            最近最不经常使用算法，从所有的键中选择某段时间之内使用频次最少的键值对清除；
        allkeys-random 检测全库数据
            所有的键中，随机选择键进行删除；
        noeviction
            不做任何的清理工作，在redis的内存超过限制之后，所有的写入操作都会返回错误；但是读操作都能正常的进行；
    FIFO（FirstInFirstOut，先进先出）根据缓存被存储的时间，离当前最远的数据优先被淘汰；
    LRU（LeastRecentlyUsed，最近最少使用）根据最近被使用的时间，离当前最远的数据优先被淘汰；
    LFU（LeastFrequentlyUsed，最不经常使用）在一段时间内，缓存数据被使用次数最少的会被淘汰

Cluster集群和分片
    常见的数据分区算法
        哈希取模
            对选择的partitioningkey计算其哈希值，得到的哈希值就是对应的分区
        范围分片
            通过确定分区键是否在某个范围内来选择分区
        一致性Hash分区
            rediscluster集群没有采用一致性哈希方案，而是采用【数据分片】中的哈希槽来进行数据存储与读取的
    什么是Redis的哈希槽slot
        Redis集群预分好16384个桶，当需要在Redis集群中放置一个key-value时，根据CRC16(key)mod16384 的值，决定将一个key放到哪个桶中

Client-Side-Caching客户端缓存
    类似浏览器缓存一样
    redis在服务端记录访问的连接和相关的key，当key有变化时通知相应的应用
    应用收到请求后自行处理有变化的key，进而实现clientcache与redis的一致
    这需要客户端实现，目前lettuce对其进行了支持

性能指标与监控
    性能指标：Performance
        latency 响应请求的平均时间
        instantaneous_ops_per_sec 平均每秒处理请求总数量
        hit_rate(calculated) 缓存查询命中率（通过查询总次数与查询得到非nil数据总次数计算而来）
    内存指标：Memory
        used_memory 当前内存使用量
        mem_fragmentation_ratio 内存碎片率（关系到是否进行碎片整理）
        evicted keys 为避免内存溢出删除的key的总数量
        blocked clients 基于阻塞操作（BLPOP等）影响的客户端数量
    基本活动指标：Basicactivity
        connected_clients 当前客户端连接总数
        connected slaves 当前连接slave总数
        master_last_io_seconds_ago 最后一次主从信息交换距现在的秒数
        keyspace key的总数
    持久性指标：Persistence
        rdb_last_save_time 当前服务器最后一次RDB持久化的时间
        rdb_changes_since_last save 当前服务器最后一次RDB持久化后数据变化总量
    错误指标：Error
        rejected_connections 被拒绝连接的客户端总数（基于达到最大连接值的因素）
        keyspace_misses key未命中的总次数
        master_link_down_since_seconds ，主从断开的秒数
    benchmark
        测试当前服务器的并发性能
        redis-benchmark [-h] [-p] [-c] [-n <requests]> [-k]
        100个连接，5000次请求对应的性能
        redis-benchmark -c 100 -n 5000
缓存一致性
    Cache Aside
        有缓存调用者自己维护数据库与缓存的一致性。！
        查询时：命中则直接返回，未命中则查询数据库并写入缓存
        更新时：更新数据库并删除缓存，查询时自然会更新缓存
    Read/writeThrough
        数据库自己维护一份缓存，底层实现对调用者透明。
        查询时：命中则直接返回，未命中则查询数据库并写入缓存
        更新时：判断缓存是否存在，不存在直接更新数据库。存在则更新缓存，同步更新数据库
    Write Behind Cahing:
        读写操作都直接操作缓存，由线程异步的将缓存数据同步到数据库
    基于binlog方案
        更新db数据
        通过canal中间件监听mysqlbinlog，同时将数据同步到 消息队列
        启动一个数据处理应用，消费消息队列数据并进行数据加工
        将加工后的数据写人redis和es 查询redis数据返回
        优点：
            方案比较松耦合，比较适合大公司的高并发业务
        缺点：
            引入了多个中间件，比如canal、kafka，还引人了数据处理程序，比较复杂.
    延迟双删方案
        先进行缓存清除
        再执行update sql.最后（延迟N秒）再执行缓存清除。
        上述中（延迟N秒）的时间要大于一次写操作的时间，一般为3-5秒，
        原因：如果延迟时间小于写人redis的时间，会导致请求1清除了缓存，但是请求2缓存还未写人的尴尬.
        注意：一般写入的时间会远小于5秒
        优点：
            方案相对比较简单，对于非高并发业务比较适合
        缺点：
            有等待环节，如果系统要求低延时，这种场景就不合适
            不适合秒杀这种频繁修改数据和要求数据强一致的场景
            延时时间是一个预估值，不能确保mysql和redis数据在这个时间段内都实时同步或持久化成功了
    基于定时任务方案
        更新db数据，同时写人数据到redis
        启动一个定时任务定时将db数据同步到redis
        前端发起接口查询请求
        先从redis查询数据
        redis没有数据，加一个分布式锁，
        再从redis数据查询查询redis数据返回
        优点：
            方案相对比较简单对于高并发业务比较适合。相对是一个比较高可用的方案，通过定时任务定时更新db数据到redis，保持数据的一致性.
    自动或手工补偿方案
        优点：
            对于适合秒杀类业务，另外通过定时任务自动补偿和手工补偿
            这种方案高可用方面做的比较好
            甚至能做到自动修复不一致性的场景
        缺点：
            需要开发额外的定时任务
    先删除后更新数据： 可能存在不一致性
    先更新再删除 推荐


分布式锁
    Mysql 做分布式锁弊端
    当查询某条记录时，就让数据库为该记录加锁，锁住记录后别人无法操作。
    一般提前采用 select for update，提前加上锁。不过并发环境下容易出现死锁。
    当命中索引 锁 的是行 没命中索引 锁 的是表
    当减库存和高并发读写碰到一起的时候，由于操作的库存数目在同一行，就会出现争抢
    InnoDB 行锁 的问题，导致出现互相等待甚至死锁，从而大大降低mysql的处理性能
    缺点：可能出现死锁，并发性能差。
    解决方案
        redis分段预扣库存和异步消息写入db
        申请阶段：
            将库存扣减从mysql前移到Redis中
            所有的预减库存的操作放到redis中，由于Redis中不存在锁，因此不会出现互相等待，并且由于Redis的写性能和读性能都远高于mysql
            这就解决了高并发下的性能问题。
            为了提高并发能力，一般对redis 锁进行分段处理。
        确认阶段：
            通过mq等异步手段，将变化的数据异步写人到DB中。
            引人mq，数据通过mq排序，按照次序更新到DB中，完全串行处理。
            当达到库存阀值的时候就不在消费队列，并关闭购买功能
            这样就解决了商品超卖问题。
            缺点：
                由于异步写入DB，可能存在数据不一致的风险，所以需要设计相应的告警机制和补偿措施。
    常见问题
        如何防止释放别的线程锁
            拿到了锁但是此时A线程执行完业务逻辑之后，还是会去释放锁（删除key），这就导致B线程的锁被A线程给释放了。
            给锁设置一个当前线程id或uuid的值，释放锁的时候判断锁的值与当前的值是否相等。相等才释放锁
        锁到期了，业务没执行完，如何保证数据的一致
            引入看门狗机制实现 对 长时间的业务资源进行锁续期
        怎么保证分布式锁可重人
            可重入锁的要点是对于同一线程可以多次获取锁，不同线程之间同一把锁不能重复获取。
            怎么保证线程可重入获取锁呢？
                答：通过维护当前持有锁的计数来实现可重入功能。
                加锁的时候，第一次获取锁时保存锁的线程标识，后续再次获取锁
                先看是否是同一个线程，如果是的话只对锁计数进行递增。
                解锁时，对锁计数进行递减，同时刷新锁的过期时间．如果计数为0
                最终才释放锁。
        如何优化高并发下锁性能
            与ConcurrentHashMap的设计思想有点类似，用分段锁来实现。
            避免使用复杂度过高的命令
            操作 bigkey
            内存碎片整理
            fork操作优化
            内存大页配置
Pipeline
    Redispipeline是一种用于提高性能的技术
    它可以一次性执行多条命令，而不必等待每个命令的响应。
    这种技术被称为流水线已经使用了几十年。
    例如，许多POP3协议实现已经支持这种功能，大大加快了从服务器下载新电子邮件的过程。
    Redis从早期开始就支持流水线，因此无论你运行的是哪个版本，都可以使用流水线与Redis一起使用。
    redisTemplate.executePipelined
    优点
        Redis pipeline的主要优点是它可以大大提高性能
        由于它允许你一次性执行多条命令，而不必等待每个命令的响应，因此它可以减少网络延迟对性能的影响。
        这对于需要在一行中执行许多请求的客户端（例如，将许多元素添加到同一列表中，或使用许多键填充数据库）非常有用。
    缺点
        Redis pipeline的一个潜在缺点是它不是原子的。
        这意味着如果你在pipeline中执行多个命令，那么这些命令将不会作为一个整体执行。
        如果在执行pipeline中的命令时出现错误，那么可能只有部分命令被执行。
        此外，如果你在pipeline中包含太多命令，可能会导致响应结果撑爆Socket接收缓冲区。
        因此，你应该控制每次pipeline中的命令数量。

防重提交

分布式限流

延迟任务

集群
    分片
        如何将同一类数据固定的保存在同一个Redis实例？
            这一类数据使用相同的有效部分，例如key都以{typeld}为前缀


布隆过滤器
    布隆过滤是一种数据统计的算法，用于检索一个元素是否存在一个集合中
    当布隆过滤器认为元素不存在的时候，它肯定是不存在的
    当布隆过滤器认为元素存在的时候，它可能存在，也可能不存在
    位图：int[10]
    每个int类型的整数是4*8=32个bit，则int[10]一共有320bit，每个bit非0即1，初始化时都是0
    添加数据时：将数据进行hash得到hash值，对应到bit位，将该bit改为1
    hash函数可以定义多个，则一个数据添加会将多个（hash函数个数）bit改为1
    多个hash 函数的目的是减少hash碰撞的概率
    查询数据：hash函数计算得到hash值
    对应到bit中，如果有一个为0，则说明数据不在bit中，如果都为1，则该数据可能在bit中

linux内存分配策略
    0
        表示内核将检查是否有足够的可用内存供应用进程使用；
        如果有足够的可用内存内存申请允许；
        否则内存申请失败并把错误返回给应用进程
    1
        表示内核允许分配所有的物理内存而不管当前的内存状态如何
    2
        表示内核允许分配超过所有物理内存和交换空间总和的内存
    设置方式
        echo1>/proc/sys/vm/overcommit_memory

QPS
同步
    主从第一次同步是全量同步，但如果slave重启后同步，则执行增量同步
    全量同步
        bg save 发生RDB 文件
    增量同步
        repl_baklog



集群主从
    各个节点会互相通信，采用gossip协议交换节点元数据信息