JDK
    Java标准开发包
    它提供了编译运行Java程序所需的各种工具和资源
    包括Java编译器
    Java运行时环境
    以及常用的Java类库等
JRE
    Java运行环境用于运行Java的字节码文件
JVM
    Java虚拟机是JRE的一部分
    它是整个java实现跨平台的最核心的部分负责运行字节码文件

hashCode 与 equals
    在Java中每个对象都可以调用自己的hashCode方法得到自己的哈希值（hashCode)
    相当于对象的指纹信息通常来说世界上没有完全相同的两个指纹
    但是在Java中做不到这么绝对
    但是我们仍然可以利用hashCode来做一些提前的判断
    比如如果两个对象的hashCode不相同那么这两个对象肯定不同的两个对象
    图如果两个对象的hashCode相同
    不代表这两个对象一定是同一个对象也可能是两个对象
    如果两个对象相等那么他们的hashCode就一定相同
    所以我们就需要注意如果我们重写了equals方法
    那么就要注意hashCode方法一定要保证能遵守上述规则
    减少hash冲突
    如果只重写equals方法，不重写hashCode方法
    就有可能导致 a.equals(b)这个表达式成立但是 hashCode却不同
    equals和hashCode是用来协同判断两个对象是否相等的
    如果只重写了equals方法，而不重写 hashCode，就会导致某些场景下程序异常。
    比如给Set中插入两个对象时
    因为这两个对象引用地址不同
    但属性值都相同
    那么正常情况下，因为不能重复插入才对。
    然而，因为未重写hashCode，所以导致判断hashCode不同
    就认为它们是不同的对象，这样就会将两个相同的对象都存储到Set集合中
    这显然是有问题的
    因为使用Set集合就是用来去重的
    结果还存入了两个相同的对象。


String String Buffer String Builder
    String是不可变的如果尝试去修改会新生成一个字符串对象
    StringBuffer和StringBuilder是可变的
    StringBuffer是线程安全的
    StringBuilder是线程不安全的
    所以在单线程环境下StringBuilder效率会更高
== 与 equals
    ==如果是基本数据类型比较是值如果是引用类型比较的是引用地址
    equals具体看各个类重写equals方法之后的比较逻辑
    比如String类虽然是引用类型但是String类中重写了equals方法方法内部比较的是字符串中的各个字符是否全部相等

ApplicationContext和BeanFactory有什么区别
    BeanFactory是Spring中非常核心的组件表示Bean工厂
    可以生成Bean维护Bean而ApplicationContext继承了BeanFactory
    所以ApplicationContext拥有BeanFactory所有的特点也是一个Bean工厂
    但是ApplicationContext除开继承了BeanFactory之外
    还继承了诸如EnvironmentCapable、MessageSource、ApplicationEventPublisher 等接口
    从而ApplicationContext还有获取系统环境变量、国际化、事件发布等功能这是BeanFactory所不具备的

HashMap
    1.7
        1.7中底层是数组+链表
        1.7中链表插入使用的是头插法
        1.7中哈希算法比较复杂，存在各种右移与异或运算
    1.8
        1.8中底层是数组+链表+红黑树，加红黑树的目的是提高HashMap插入和查询整体效率
        1.8中链表插入使用的是尾插法
        因为1.8中插入key和value时需要判断链表元素个数
        所以需要遍历链表统计链表元素个数，所以正好就直接使用尾插法
        1.8中进行了简化，因为复杂的哈希算法的目的就是提高散列性，来提供HashMap的整体效率
        而1.8中新增了红黑树，所以可以适当的简化哈希算法
        节省CPU资源

HashMap Put操作
    先说HashMap的Put方法的大体流程：
    1.根据Key通过哈希算法与与运算得出数组下标
    2.如果数组下标位置元素为空，则将key和value封装为Entry对象
    （JDK1.7中是Entry对象，JDK1.8中是Node对象）并放入该位置
    3.如果数组下标位置元素不为空，则要分情况讨论
        a.如果是JDK1.7，则先判断是否需要扩容，如果要扩容就进行扩容，如果不用扩容就生成Entry对象，并使用头插法添加到当前位置的链表中
        b.如果是JDK1.8，则会先判断当前位置上的Node的类型，看是红黑树Node，还是链表Node
            如果是红黑树Node，则将key和value封装为一个红黑树节点并添加到红黑树中去
            在这个过程中会判断红黑树中是否存在当前key，如果存在则更新value
            如果此位置上的Node对象是链表节点，则将key和value封装为一个链表Node并通过尾插法插入到链表的最后位置去
            因为是尾插法所以需要遍历链表
            在遍历链表的过程中会判断是否存在当前key，如果存在则更新value
            当遍历完链表后将新链表Node插入到链表中
            插入到链表后会看当前链表的节点个数如果大于等于8那么则会将该链表转成红黑树
            将key和value封装为Node插入到链表或红黑树中后
            再判断是否需要进行扩容如果需要就扩容
            如果不需要就结束PUT方法

HashMap的扩容机制原理
    1.7版本
        1.先生成新数组
        2.遍历老数组中的每个位置上的链表上的每个元素
        3.取每个元素的key，并基于新数组长度，计算出每个元素在新数组中的下标
        4.将元素添加到新数组中去
        5.所有元素转移完了之后，将新数组赋值给HashMap对象的table属性
    1.8版本
        1.先生成新数组
        2.遍历老数组中的每个位置上的链表或红黑树
        3.如果是链表，则直接将链表中的每个元素重新计算下标，并添加到新数组中去
        4.如果是红黑树，则先遍历红黑树，先计算出红黑树中每个元素对应在新数组中的下标位置
            a.统计每个下标位置的元素个数
            b.如果该位置下的元素个数超过了8，则生成一个新的红黑树，并将根节点的添加到新数组的对应位置
            c.如果该位置下的元素个数没有超过8，那么则生成一个链表，并将链表的头节点添加到新数组的对应位置
        5.所有元素转移完了之后，将新数组赋值给HashMap对象的table属性

ConcurrentHashMap
    1.7版本
    ConcurrentHashMap在JDK1.7时，使用的是分段锁也就是Segment来实现线程安全的
        1.7版本的ConcurrentHashMap是基于Segment分段实现的
        2.每个Segment相对于一个小型的HashMap
        3.每个Segment内部会进行扩容，和HashMap的扩容逻辑类似
        4.先生成新的数组，然后转移元素到新数组中
        5.扩容的判断也是每个Segment内部单独判断的，判断是否超过阈值
        ConcurrentHashMap在JDK1.7中它使用的是数组加链表的形式实现的
        而数组又分为：大数组Segment和小数组HashEntry。
            大数组Segment可以理解为MySQL中的数据库，而每个数据库（Segment）中又有很多张表HashEntry
            每个HashEntry中又有多条数据
            这些数据是用链表连接
    1.8版本
    ConcurrentHashMap在JDK1.8之后，使用的是CAS+synchronized或CAS+volatile来实现线程安全的。
        1.8版本的ConcurrentHashMap不再基于Segment实现
        2.当某个线程进行put时，如果发现ConcurrentHashMap正在进行扩容那么该线程一起进行扩容
        3.如果某个线程put时，发现没有正在进行扩容则将key-value添加到ConcurrentHashMap中
        然后判断是否超过阈值超过了则进行扩容
        4.ConcurrentHashMap是支持多个线程同时扩容的
        5.扩容之前也先生成一个新的数组
        6.在转移元素时，先将原数组分组
            将每组分给不同的线程来进行元素的转移
            每个线程负责一组或多组的元素转移工作
        在JDK1.7中，ConcurrentHashMap虽然是线程安全的，但因为它的底层实现是数组+链表的形式
        所以在数据比较多的情况下访问是很慢的，因为要遍历整个链表
        而JDK1.8则使用了数组+链表/红黑树的方式优化了
        降低了 加锁范围 在树的头节点枷锁 / 链表 Node 节点加锁
        比 原来1.7 直接在Segment段加锁降低了加锁范围

        在JDK1.8中，添加元素时首先会判断容器是否为空
        如果为空则使用volatile加CAS来初始化。
        如果容器不为空则根据存储的元素计算该位置是否为空，如果为空则利用CAS设置该节点；
        如果不为空则使用synchronize加锁，遍历桶中的数据，替换或新增节点到桶中
        最后再判断是否需要转为红黑树，这样就能保证并发访问时的线程安全了。
        我们把上述流程简化一下
            我们可以简单的认为在JDK1.8中，ConcurrentHashMap是在头节点加锁来保证线程安全的
            锁的粒度相比Segment来说更小了
            发生冲突和加锁的频率降低了
            并发操作的性能就提高了。
            而且JDK1.8使用的是红黑树优化了之前的固定链表，那么当数据量比较大的时候
            查询性能也得到了很大的提升，从之前的O（n）优化到了O（logn）的时间复杂度

Java 死锁
    造成死锁的几个原因：
        1.一个资源每次只能被一个线程使用
        2.一个线程在阻塞等待某个资源时，不释放已占有资源
        3.一个线程已经获得的资源，在未使用完之前，不能被强行剥夺
        4.若干线程形成头尾相接的循环等待资源关系
    这是造成死锁必须要达到的4个条件
        如果要避免死锁只需要不满足其中某一个条件即可
        而其中前3个条件是作为锁要符合的条件
        所以要避免死锁就需要打破第4个条件，不出现循环等待锁的关系
    在开发过程中：
        1.要注意加锁顺序，保证每个线程按同样的顺序进行加锁
        2.要注意加锁时限，可以针对所设置一个超时时间
        3.要注意死锁检查，这是一种预防机制，确保在第一时间发现死锁并进行解决
        可以通过jstack来查看线程的运行情况，比如哪些线程阻塞、是否出现了死锁

Java中的异常体系
    Java中的所有异常都来自顶级父类Throwable
    Throwable下有两个子类Exception和Error
    Error表示非常严重的错误，比如java.lang.StackOverFlowError和Java.lang.OutOfMemoryError，通常这些错误出现时
    仅仅想靠程序自己是解决不了的
    可能是虚拟机、磁盘、操作系统层面出现的问题了
    所以通常也不建议在代码中去捕获这些Error，因为捕获的意义不大，因为程序可能已经根本运行不了了
    Exception表示异常，表示程序出现Exception时，是可以靠程序自已来解决的
    比如NullPointerException、IllegalAccessException等，我们可以捕获这些异常来做特殊处理
    Exception的子类通常又可以分为RuntimeException和非RuntimeException两类
    RunTimeException表示运行期异常，表示这个异常是在代码运行过程中抛出的，这些异常是非检查异常，程序中可以选择捕获处理，也可以不处理
    这些异常一般是由程序逻辑错误引引起的，程序应该从逻辑角度尽可能避免这类异常的发生
    比如NullPointerException、IndexOutOfBoundsException等
    非RuntimeException表示非运行期异常，也就是我们常说的检查异常，是必须进行处理的异常
    如果不处理，程序就不能检查异常通过。如IOException、SQLException等以及用户自定义的Exception异常

Java类加载器
    JDK自带有三个类加载器：bootstrapClassLoader、ExtClassLoader、AppClassLoader
    BootStrapClassLoader是ExtClassLoader的父类加载器
    默认负责加载%JAVA_HOME%lib下的jar包和class文件
    ExtClassLoader是AppClassLoader的父类加载器负责加载%JAVA_HOME%/lib/ext文件夹下的jar包和class类
    AppClassLoader是自定义类加载器的父类，负责加载classpath下的类文件.
类加载器双亲委派模型
    AppClassLoader的父加载器是ExtClassLoader，ExtClassLoader的父加载器是BootstrapClassLoader
    JVM在加载一个类时
    会调用AppClassLoader的loadClass方法来加载这个类
    不过在这个方法中，会先使用ExtClassLoader的loadClass方法来加载类
    同样ExtClassLoader的loadClass方法中会先使用BootstrapClassLoader来加载类
    如果BootstrapClassLoader加载到了就直接成功
    如果BootstrapClassLoader没有加载到，那么ExtClassLoader 就会自己尝试加载该类
    如果没有加载到，那么则会由AppClassLoader来加载这个类
    所以双亲委派指得是JVM在加载类时会委派给Ext和Bootstrap进行加载如果没加载到才由自己进行加载

JVM 垃圾回收算法
    1.标记清除算法：
        a.标记阶段：把垃圾内存标记出来
        b.清除阶段：直接将垃圾内存回收
        c.这种算法是比较简单的，但是有个很严重的问题，就是会产生大量的内存碎片
    2.复制算法：为了解决标记清除算法的内存碎片问题，就产生了复制算法
        复制算法将内存分为大小相等的两半，每次只使用其中一半
        垃圾回收时，将当前这一块的存活对象全部拷贝到另一半
        然后当前这一半内存就可以直接清除
        这种算法没有内存碎片，但是他的问题就在于浪费空间
        而且他的效率跟存活对象的个数有关
    3.标记压缩算法：为了解决复制算法的缺陷，就提出了标记压缩算法
        这种算法在标记阶段跟标记清除算法是一样的，但是在完成标记之后
        不是直接清理垃圾内存，而是将存活对象往一端移动然后将边界以外的所有内存直接清除
STW
    STW:Stop-The-World，是在垃圾回收算法执行过程当中，需要将JVM内存冻结的一种状态。
    在STW状态下，JAVA的所有线程都是停止执行的-GC线程除外
    native方法可以执行但是不能与JVM交互。
    GC各种算法优化的重点就是减少STW
    同时这也是JVM调优的重点
一个对象从加载到JVM，再到被GC清除，都经历了什么过程？
    1.首先把字节码文件内容加载到方法区
    2.然后再根据类信息在堆区创建对象
    3.对象首先会分配在堆区中年轻代的Eden区，经过一次MinorGC后，对象如果存活
        就会进入Suvivor区。
        在后续的每次MinorGC中，如果对象一直存活
        就会在 Suvivor区来回拷贝
        每移动一次，年龄加1
    4.当年龄超过15后，对象依然存活，对象就会进入老年代
    5.如果经过FulGC，被标记为垃圾对象，那么就会被GC线程清理掉
    而4个bt位能够存储的最大数值是15JVM分代年龄之所以设置成IS次
JVM参数
    JVM参数大致可以分为三类：
        1.标注指令：-开头，这些是所有的HotSpot都支持的参数。可以用java-help打印出来。
        2.非标准指令：-x开头，这些指令通常是跟特定的HotSpot版本对应的。可以用java-X打印出来。
        3.不稳定参数：-Xx开头，这一类参数是跟特定HotSpot版本对应的，并且变化非常大。
JVM 线程共享
    堆区和方法区是所有线程共享的
    栈、本地方法栈、程序计数器是每个线程独有的

Mybatis
    #
        #是预编译处理、是占位符
        Mybatis在处理#时会将sql中的#替换为？号，调用PreparedStatement来赋值；
        使用#可以有效的防止SQL注入，提高系统安全性。
    $
        $是字符串替换、是拼接符
        Mybatis在处理$时，会将sql中的$替换成变量的值，调用Statement来赋值；

Mybatis中的一级缓存 二级缓存
    一级缓存
        SglSession级别 就是一次查询一次事务就认为是一个SqlSession缓存结果在这个过程中是共享的只在一次数据库的事务里面有效
    二级缓存
        整个mapper的这个命名空间不管你是哪一次的事务产生的从一次会话的这个结果共享变成了所有的会话的结果共享

CountDownLatch 和 Semaphore的区别和底层原理
    CountDownLatch表示计数器，可以给CountDownLatch设置一个数字
    一个线程调用CountDownLatch的await将会阻塞
    其他线程可以调用CountDownLatch的 countDown方法来对CountDownLatch中的数字减一
    当数字被减成0后所有await的线程都将被唤醒。
    对应的底层原理就是
        调用await方法的线程会利用AQS排队
        一旦数字被减为0则会将AQS中排队的线程依次唤醒。
    Semaphore表示信号量，可以设置许可的个数，表示同时允许最多多少个线程使用该信号量
    通过acquire来获取许可
    如果没有许可可用则线程阻塞
    并通过AQS来排队可以通过release方法来释放许可
    当某个线程释放了某个许可后
    会从AQS中正在排队的第一个线程开始依次唤醒
    直到没有空闲许可。

Sychronized
    1.偏向锁：在锁对象的对象头中记录一下当前获取到该锁的线程ID，该线程下次如果又来获取该锁就可以直接获取到了
    2.轻量级锁：由偏向锁升级而来
        当一个线程获取到锁后，此时这把锁是偏向锁
        此时如果有第二个线程来竞争锁，偏向锁就会升级为轻量级锁
        之所以叫轻量级锁，是为了和重量级锁区分开来
        轻量级锁底层是通过自旋来实现的并不会阻塞线程
    3.如果自旋次数过多仍然没有获取到锁，则会升级为重量级锁，重量级锁会导致线程阻塞
    4.自旋锁：自旋锁就是线程在获取锁的过程中，不会去阻塞线程
    也就无所谓唤醒线程，阻塞和唤醒这两个步骤都是需要操作系统去进行的，比较消耗时间
    自旋锁是线程通过CAS获取预期的一个标记，如果没有获取到，则继续循环获取
    如果获取到了则表示获取到了锁
    这个过程线程一直在运行中，相对而言没有使用太多的操作系统资源，比较轻量。

ReentrantLock
    1.tryLock表示尝试加锁，可能加到，也可能加不到，该方法不会阻塞线程，如果加到锁则返回true，没有加到则返回false
    2.lock表示阻塞加锁，线程会阻塞直到加到锁，方法也没有返回值

ReentrantLock 公平锁 非公平锁
    首先不管是公平锁和非公平锁，它们的底层实现都会使用AQS来进行排队，
    它们的区别在于：线程在使用lock方法加锁时
        如果是公平锁，会先检查AQS队列中是否存在线程在排队，如果有线程在排队，则当前线程也进行排队
        如果是非公平锁，则不会去检查是否有线程在排队，而是直接竞争锁。
    不管是公平锁还是非公平锁，一旦没竞争到锁，都会进行排队，当锁释放时，都是唤醒排在最前面的线程
    所以非公平锁只是体现在了线程加锁阶段
    而没有体现在线程被唤醒阶段。
    ReentrantLock是可重入锁，不管是公平锁还是非公平锁都是可重入的。

Sychronized和ReentrantLock的区别
    1.sychronized是一个关键字，ReentrantLock是一个类
    2.sychronized会自动的加锁与释放锁，ReentrantLock需要程序员手动加锁与释放锁
    3.sychronized的底层是JVM层面的锁，ReentrantLock是APi层面的锁
    4.sychronized是非公平锁，ReentrantLock可以选择公平锁或非公平锁
    5.sychronized锁的是对象，锁信息保存在对象头中，ReentrantLock通过代码中int类型的state标识来标识锁的状态
    6.sychronized底层有一个锁升级的过程
    7. sychronized锁释放是被动的 synchronized只有代码块执行结束 代码执行出现异常的时候 才会去释放锁

谈谈你对AQS的理解，AQS如何实现可重入锁？
    1 AQS是一个JAVA线程同步的框架。是JDK中很多锁工具的核心实现框架。
    2.在AQS中，维护了一个信号量state和一个线程组成的双向链表队列。
        其中，这个线程队列，就是用来给线程排队的
        而state就像是一个红绿灯，用来控制线程排队或者放行的。
        在不同的场景下，有不用的意义。
    3.在可重入锁这个场景下
        state就用来表示加锁的次数。
        0标识无锁，每加一次锁，state就加1。
        释放锁state就减1。

TCP的三次握手和四次挥手
    TCP协议是7层网络协议中的传输层协议负责数据的可靠传输。
    在建立TCP连接时，需要通过三次握手来建立
    过程是：
        1.客户端向服务端发送一个SYN
        2.服务端接收到SYN后，给客户端发送一个SYN_ACK
        3.客户端接收到SYN_ACK后，再给服务端发送一个ACK
    在断开TCP连接时，需要通过四次挥手来断开
    过程是：
        1.客户端向服务端发送FIN
        2.服务端接收FIN后，向客户端发送ACK，表示我接收到了断开连接的请求，客户端你可以不发数据了，不过服务端这边可能还有数据正在处理
        3.服务端处理完所有数据后，向客户端发送FIN，表示服务端现在可以断开连接
        4.客户端收到服务端的FIN，向服务端发送ACK，表示客户端也会断开连接了

浏览器发出一个请求到收到响应经历了哪些步骤？
    1.浏览器解析用户输入的URL，生成一个HTTP格式的请求
    2.先根据URL域名从本地hosts文件查找是否有映射IP，如果没有就将域名发送给电脑所配置的DNS进行域名解析，得到IP地址
    3.浏览器通过操作系统将请求通过四层网络协议发送出去
    4.途中可能会经过各种路由器、交换机，最终到达服务器
    5.服务器收到请求后，根据请求所指定的端口，将请求传递给绑定了该端口的应用程序，比如8080被tomcat占用了
    6.tomcat接收到请求数据后，按照http协议的格式进行解析，解析得到所要访问的servlet
    7.然后servlet来处理这个请求，如果是SpringMVC中的DispatcherServlet，那么则会找到对应的Controller中的方法，并执行该方法得到结果
    8.Tomcat得到响应结果后封装成HTTP响应的格式，并再次通过网络发送给浏览器所在的服务器
    9.浏览器所在的服务器拿到结果后再传递给浏览器，浏览器则负责解析并渲染

ThreadLocal的底层原理
    1.ThreadLocal是Java中所提供的线程本地存储机制，可以利用该机制将数据缓存在某个线程内部，该线程可以在任意时刻、任意方法中获取缓存的数据
    2.ThreadLocal底层是通过ThreadLocalMap来实现的
        每个Thread对象（注意不是ThreadLocal对象）中都存在一个ThreadLocalMap
        Map的key为ThreadLocal对象，Map 的value为需要缓存的值
    3.如果在线程池中使用ThreadLocal会造成内存泄漏，因为当ThreadLocal对象使用完之后，应该要把设置的key，value，也就是Entry对象进行回收
    但线程池中的线程不会回收，而线程对象是通过强引用指向ThreadLocalMap
    ThreadLocalMap也是通过强引I用指向Entry对象
    线程不被回收，Entry对象也就不会被回收，从而出现内存泄漏
    解决办法是，在使用了ThreadLocal对象之后
        手动调用ThreadLocal的remove方法，手动清楚Entry对象
    4.ThreadLocal经典的应用场景就是连接管理（一个线程持有一个连接，该连接对象可以在不同的方法之间进行传递，线程之间不共享同一个连接）

线程池的底层工作原理
    线程池内部是通过队列+线程实现的，当我们利用线程池执行任务时：
    1.如果此时线程池中的线程数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。
    2.如果此时线程池中的线程数量等于corePoolSize，但是缓冲队列workQueue未满，那么任务被放入缓冲队列
    3.如果此时线程池中的线程数量大于等于corePoolSize，缓冲队列workQueue满
        并且线程池中的数量小于maximumPoolSize，建新的线程来处理被添加的任务。
    4.如果此时线程池中的线程数量大于corePoolSize，缓冲队列workQueue满
        并且线程池中的数量等于maximumPoolSize，那么通过handler所指定的策略来处理此任务。
    5.当线程池中的线程数量大于corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。
        这样，线程池可以动态的调整池中的线程数
线程池为什么是先添加列队而不是先创建最大线程？
    当线程池中的核心线程都在忙时
    如果继续往线程池中添加任务
    那么任务会先放入队列，队列满了之后，才会新开线程。
    这就相当于
        一个公司本来有10个程序员
        本来这10个程序员能正常的处理各种需求
        但是随着公司的发展需求在慢慢的增加
        但是一开始这些需求只会增加在待开发列表中
        然后这10个程序员加班加点的从待开发列表中获取需求并进行处理但是某一天待开发列表满了
        公司发现现有的10个程序员是真的处理不过来了
        所以就开始新招员工了
    线程池初始化
        向线程池里面添加任务的时候被动初始化
        主动调用 prestartAllCoreThreads方法


volatile
    1 可以保证在多线程环境下共享变量的可见性
    2 通过增加内存屏障防止多个指令之间的重排序

可重入
    简单来说呢就是说在运行的某个函数或者代码因为抢占资源或者中断导致这个函数或者代码运行过程中被中断了
    那么等到中断的程序执行结束以后重新进入到这个函数的代码里面再运行的时候并且运行的结果不会发生变化
    那么这个函数或者代码就是可重入的

    简单来说就是说一个线程如果抢占到了互房锁的资源在锁释放之前再去竞争同一把锁的时候不需要等待只需要去记录重入次数

强引用 软引用 弱引用 虚引用
    主要体现的是对象不同的可达性状态和对于垃圾收集的影纫响
    强引用 就是普通对象引用,不会被垃圾回收器回收
    软引用 内存不足时回收 只有当JVM认为内存不足的时候才会去试图回收引用指向的对象
    弱引用 发现即回收
    虚引用 它不会决定对象的生命周期它提供一种确保对象被finalize以后去做某些事情的一种机制就会在回收对象的内存之前啊

finally语句块在两种情况下不会执行
    1、程序没有进入到try语句块因为异常导致程序终止，这个问题主要是开发人员在编写代码的时候，异常捕获的范围不够
    2、在try或者cache语句块中，执行了System.exit（O）语句，导致JVM直接退出
    3. 不在 try {} 语句块当中 在try之前 return
    4. 异常没有被 catch 捕获住 在try之前就发生异常了

return 与 finally
    1. return 与 finally 同时存在 先执行 finally 再执行 return
    2. return 返回变量时 try 语句块里变量(代码走到这里会把 变量 暂存 然后执行finaLLy 最后再返回 变量)
        try、catch有return情况，先将结果保存在临时栈中，再去执行finally，最后返回
    3. finally 捕获语句块中有 return 就直接返回 finally 中 return 数据 (这里的return优先于try里的return)
        如果finally中也有return那么将直接返回finally中的return

final finalize的区别
    final
        说明这个变量是一个常量，意味着它的值在初始化之后不能再次改变
        说明这个方法不能被重写，但是不影响继承这个方法
        说明这个类不能被继承，所以不能使用 final和abstract来修饰同一个类，同样的，final也不能用来修饰接口
    finalize
        finalize通常指的是finalize方法，它是 Object类的方法
        是在对象被垃圾回收器回收之前调用的
        我们可以通过重写这个 finalize0方法，给对象自己最后一个复活的机会
        但是不能保证finalizeO方法立即执行什么时候调用具体由虚拟机决定
SPI
    机制的主要思想呢是把装配的控制权转移到了程序之外完成标准和实现的一个解耦
    以及提供一个动态可插拔的扩展能力
    1. 需要先定义一个接口作为扩展的标准
    2. 在classpath目录下创建META-INF/service文件目录
        在这个目录下以接口的全限定名命名的配置文件文件内容是这个接口的实现类
    3. 在应用程序里面，使用ServiceLoad根据接口名称找到classpath所有的扩展时间

HashTable
    基于hash表实现的 K-V结构的集合线程安全的集合类基于 Synchronized同步锁 数组+链表
    HashMap可以使用null作为key而 HashTable的键和值都不能为null，否则会抛出NullPointerException

SortedSet
    有序集合
    不允许元素有重复
    按照元素的自然顺序或者自定文比较器进行排序
    元素的添加和删除操作的时间复杂度为O(logn)

如何破坏双亲委派模型
    重写ClassLoader里面的loadclassl方法
    使用findClass方法
    使用线程上下文加载器

类加载
    1.类加载检查
        虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用
        并且检查这个符号引用代表的类是否已被加载
        解析和初始化过
        如果没有，那必须先执行相应的类加载过程。
        new指令对应到语言层面上讲是
            new关键词、对象克隆、对象序列化等
    2.分配内存
        在类加载检查通过后，接下来虚拟机将为新生对象分配内存。
        对象所需内存的大小在类加载完成后便可完全确定
        为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。
        这个步骤有两个问题：
            1.如何划分内存。
                “指针碰撞”（BumpthePointer）（默认用指针碰撞）
                    如果Java堆中内存是绝对规整的，所有用过的内存都放在一边
                    空闲的内存放在另一边，中间放着一个指针作为分界点的指示器
                    那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离
                “空闲列表”（Free List)
                    如果Java堆中的内存并不是规整的
                    已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了
                    虚拟机就必须维护一个列表
                    记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例
                    并更新列表上的记录
            2.在并发情况下，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。
                CAS (compare and swap)
                    虚拟机采用CAS配上失败重试的方式保证更新操作的原子性来对分配内存空间的动作进行同步处理
                本地线程分配缓冲(Thread Local Allocation Buffer,TLAB)
                    把内存分配的动作按照线程划分在不同的空间之中进行
                    即每个线程在Java堆中预先分配一小块内存
                    通过-XX:+/-UseTLAB参数来设定虚拟机是否使用TLAB（JVM会默认开启-XX:+UseTLAB）
                    -XX：TLABSize指定TLAB大小
    3.初始化零值
        内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）
        如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。
        这一步操作保证了对象的实例字段在JaVa代码中可以不赋初始值就直接使用
        程序能访问到这些字段的数据类型所对应的零值。
    4.设置对象头
        初始化零值之后，虚拟机要对对象进行必要的设置
        例如这个对象是哪个类的实例
            如何才能找到类的元数据信息
            对象的哈希码
            对象的GC分代年龄等信息
            这些信息存放在对象的对象头ObjectHeader之中
        在HotSpot虚拟机中
            对象在内存中存储的布局可以分为3块区域
                对象头（Header）
                实例数据（InstanceData）
                和对齐填充（Padding）
                HotSpot虚拟机的对象头包括两部分信息
                    第一部分用于存储对象自身的运行时数据
                        如哈希码（HashCode）
                        GC分代年龄
                        锁状态标志
                        线程持有的锁
                        偏向线程ID
                        偏向时间戳等
                    对象头的另外一部分是类型指针
                        即对象指向它的类元数据的指针
                        虚拟机通过这个指针
                        来确定这个对象是哪个类的实例
    5.执行<init>方法
        执行<init>方法
        即对象按照程序员的意愿进行初始化。
        对应到语言层面上讲，就是为属性赋值（注意，这与上面的赋零值不同，这是由程序员赋的值）
        和执行构造方法。

String
    底层数据结构 数组 JDK9前 char[] JDK9之后 byte[] 一个char 等于2个 byte（字节），所以这样更节省内存空间
    JVM 方法区字符串常量池 利用不可变性 final
    String为什么被设计成不可变的
        1．线程安全：不可变字符串在多线程环境下天然地是线程安全的，因为多个线程无法修改它。这样就不需
        要额外的同步机制，避免了线程安全问题。
        2.安全性：不可变字符串在某种程度上可以防止意外修改。在一些情况下，如果字符串可变，可能会导致
        一些潜在的安全漏洞。
        3.重用和缓存：由于字符串不可变，可以对字符串进行缓存和重用，避免频繁创建新的字符串，从而节省
        内存和提高效率。
        4.代码设计简化：不可变字符串使得字符串操作更加简单，避免了需要频繁修改字符串带来的复杂性
    String str=new String("javacn.site")创建了几个对象
        首先，使用new 关键字，所以无论如何都会在堆上创建一个对象。
        之后会判断字符串常量池中是否有“javacn.site”字符串
        如果有的话就只创建这一个对象。
        如果没有的话就会在字符串常量池中创建一个字符串对象，并关联 堆中 new 关键字开辟出来的对象 所以就是一个或两个对象。
    String StringBuilder和StringBuffer有什么区别
        因为 String 是不可变类，所以一旦创建了String 对象，其值就不能被修改。任何对String 的操作都会返回一个新的String对象。
        所以在字符串拼接的时候如果使用String的话性能会很低
        因此我们就需要使用另一个数据类型StringBuffer，它提供了append方法可用于字符串的拼接，并使用synchronized来保证线程安全
        StringBuilder 是为了解决单线程环境下字符串拼接效率问题 由于StringBuffer被synchronized修饰导致效率不高

抽象类和接口有什么区别
    类型扩展不同：抽象类是单继承，而接口是多继承（多实现）
    方法/属性访问控制符不同
        抽象类方法和属性使用访问修饰符无限制
            只是抽象类中的抽象方法不能被 private修饰；
            而接口有限制接口默认的是public控制符不能使用其他修饰符；
    方法实现不同：抽象类中的普通方法必须有实现
    而接口中普通方法不能有实现（不考虑JDK8中defualt 默认方法）;
    职责不同：接口是为了定义规范，而抽象类是为了复用代码

什么是反射？ 它有什么用
    在Java中，反射是指在运行时检查和操作类、接口、字段、方法等程序结构的能力。
    通过反射，可以在运行时获取类的信息，创建类的实例，调用类的方法，访问和修改类的字段等。
    Spring 依赖注入
    1.性能问题：
        使用反射会带来一定的性能问题，因为反射需要在运行时动态获取类的信息，这比在编译时就获取信息要慢。
    2.安全问题：
        使用反射可以访问和修改类的字段和方法，这可能会导致安全问题。因此，在使用反射时需要格外小心，确保不会对程序的安全性造成影响。

HashMap和HashSet有什么区别
    1.HashSet实现了Set接口，只存储对象；HashMap实现了Map接口，用于存储键值对。
    2.HashSet底层是用HashMap存储的，HashSet封装了一系列HashMap的方法，HashSet将（自己的）值保存到HashMap的Key里面了。
    3.HashSet不允许集合中有重复的值（如果有重复的值，会插入失败），而HashMap键不能重复，值可以重复（如果键重复会覆盖原来的值）。
    4.HashSet可以存放nul值，但是只能有一个null Map的key可以为null,value也可以为null，注意key为null，只能有一个，value为null，可以多个

为什么HashMap负载因子为0.75
    HashMap扩容的目的是为了减少哈希冲突，提高HashMap性能
    HashMap负载因子loadfactor，也叫做扩容因子和装载因子
    它是HashMap在进行扩容时的一个闯值
    当 HashMap中的元素个数超过了容量乘以负载因子时，就会进行扩容。
    默认的负载因子是0.75，也就是说当 HashMap中的元素个数超过了容量的75%时，就会进行扩容。
    当然，我们也可以通过构造函数来指定负载因子
    简单来说是默认负载因子为0.75，是因为它提供了空间和时间复杂度之间的良好平衡。
    负载因子太低会导致大量的空桶浪费空间，负载因子太高会导致大量的碰撞，降低性能。
    0.75的负载因子在这两个因素之间取得了良好的平衡。

为什么HashMap线程不安全
    线程安全是指在多线程（并发）环境下，多个线程同时操作同一个对象时
    不会出现不符合预期的错误结果。
    然而HashMap却是线程不安全的，也就是当多个线程同时操作HashMap时，会出现不确定的错误结果
    死循环问题
        死循环问题是指在并发环境下，因为多个线程同时进行put操作，导致链表形成环形数据结构，一旦形成环形数据结构
        在get(key）的时候就会产生死循环。
        1.HashMap使用头插法进行数据插入（JDK1.8之前）
        2.多线程同时添加 链表头部元素槽位；
        3.触发了HashMap扩容。
    数据覆盖问题

        判断是否有哈希槽位与往哈希槽位存储值不是原子性的是分为两步骤的

        数据覆盖问题发生在并发添加元素的场景下，它不止出现在JDK1.7版本中，其他版本中也存在此问题，数据覆盖
        1.线程T1进行添加时，判断某个位置可以插入元素，但还没有真正的进行插入操作，自己时间片就用完了。
        2.线程T2也执行添加操作，并且T2产生的哈希值和T1相同，也就是T2即将要存储的位置和T1相同
            因为此位置尚未插入值（T1线程执行了一半），于是T2就把自己的值存入到当前位置了。
        3.T1恢复执行之后，因为非空判断已经执行完了，它感知不到此位置已经有值了
            于是就把自己的值也插入到了此位置，那么T2的值就被覆盖了。
        解决方案
            1.使用线程安全容器ConcurrentHashMap替代HashMap;
            2.使用线程安全容器Hashtable替代HashMap（此方式性能不高，不推荐使用）；
            3.在进行HashMap操作时，使用synchronized或Lock加锁执行。

TreeSet 有序的Set集合
    1.当我们使用无参构造器，创建TreeSet时，仍然是无序的

LinkedHashSet
    底层维护了一个数组+双向链表
    LinkedHashSet根据元素的hashCode值来决定元素的存储位置，同时使用链表维护元素的次序
    这使得元素看起来是以插入顺序保存的
JAVA 泛型擦除

内存泄露
    有引用指向的对象无法被GC清理的
内存溢出

dump 文件

调优
    堆溢出
    元空间溢出
    线程溢出
    观测
        运行日志
        异常堆栈信息
        线程快照
        GC日志

JVM 架构
    类加载子系统
        加载
            BootStrap ClassLoader
            Extension ClassLoader
            Application ClassLoader
        校验
        初始化
    运行时数据区
        方法区 (线程共享)
        堆 (线程共享)
        程序计数器 (线程私有)
        本地方法栈 (线程私有)
        虚拟机栈 (线程私有)
    执行引擎
    本地方法接口/本地方法库

++i / i++
    i++
        先用 i 本来的值参与运算然后再将 i+1 的值赋值给 i
    ++i
        先将 i+1 的值赋值给 i 然后再用 i 的新值参与运算
自定义类加载
    类加载
    链接
    初始化

垃圾清理回收时机
    引用计数
        优点
            实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性
        缺点
            引用计数器有一个严重的问题，即无法处理循环引用的情况 内存泄露
    可达性分析
        相对于引用计数算法而言，可达性分析算法不仅同样具备实现简单和执行高效等特点
        更重要的是该算法可以有效地解决在引用计数算法中循环引用的问题，防止内存泄漏的发生
        GC Roots
            虚拟机栈
            本地方法栈
            静态属性引用对象
            方法区常量引用对象
            被synchronized持有得对象
            java虚拟机内部引用
垃圾清理
    标记清除
        标记有引用指向不是垃圾的对象实例
        缺点
            效率低要进行递归及全堆遍历
            有内存碎片化 造成内存空间浪费
            在进行GC的时候需要亭止整个应用程序 导致JVM不可用
        何为清除？
            这里所谓的清除并不是真的置空，而是把需要清除的对象地址保存在空闲的地址列表里
            下次有新对象需要加载时，判断垃圾的位置空间是否够，如果够就存放
        选择关注点
            CMS
    标记压缩
        标记-压缩算法的最终效果等同于标记-清除算法执行完成后，再进行一次内存碎片整理
        因此，也可以把它称为标记-清除-压缩（Mark-Sweep-Compact）算法
        二者的本质差异在于标记-清除算法是一种非移动式的回收算法，标记-压缩是移动式的动回收后的存活对象是一项优缺点并存的风险决策
        JVM只需要持有一个内存的起始地址即可，这比维护一个空闲列表显然少了许多开销
        优化了标记清除过程中的碎片化,基于压缩算法归类整理出连续内存空间优化了内存利用率
    复制算法
        优点
            没有标记和清除过程实现简单运行高效
            复制过去以后保证空间的连续性不会出现“碎片”问题
        缺点
            需要两倍的内存空间
            对于G1这种分拆成为大量region的GC，复制而不是移动
            意味着Gc需要维护region之间对象引用关系不管是内存占用或者时间开销也不小
        选择关注点：
            如果系统中的存活对象很多复制算法不会很理想
            因为复制算法需要复制的存活对象数量并不会太大，或者说非常低才行
    分代收集
        分代收集算法，是基于这样一个事实：不同的对象的生命周期是不一样的
        因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率
        一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率
        年轻代（YoungGen）
            年轻代特点：区域相对老年代较小，对象生命周期短、存活率低，回收频繁
            这种情况复制算法的回收整理，速度是最快的
            复制算法的效率只和当前存活对象大小有关，因此很适用于年轻代的回收
            而复制算法内存利用率不高的问题，通过hotspot中的两个survivor的设计得到缓解
        老年代（TenuredGen）
            老年代特点：区域较大，对象生命周期长、存活率高，回收不及年轻代频繁
            这种情况存在大量存活率高的对象，复制算法明显变得不合适
            一般是由标记-清除或者是标记-清除与标记-整理的混合实现
    分区算法
    增量收集
        增量算法对基础算法的改进主要体现在该算法通过并发的方式
        降低了STW的时间
        增量算法的核心思想是：通过GC和应用程序交替执行的方式来控制应用程序的最大暂停时间
    并发收集
        并发垃圾回收算法是以基础的标记复制算法为基础
        在各个阶段增加了并发操作实现的
        与复制算法的3个阶段相对应
        分为并发标记（mark）
        并发转移（relocate）
        并发重定位（remap）

读屏障 / 写屏障
    在标记对象是否存活的过程中对象间的引用关系是不能改变的
    这对于串行GC来说是可行的
    因为此时应用程序处于STW状态
    对于并发GC来说，在分析对象引I用关系期间，对象间引用关系的建立和销毁是肯定存在的
    如果没有其他补偿手段并发标记期间就可能出现对象多标和漏标的情况
    需要引入读写屏障来解决漏指的是程序在从堆中读取引用或更新堆中引用时
    GC需要执行一些额外操作，其本质是一些同步的指令操作
    可以将读／写屏障类比于Spirng框架里的拦截器

finalize()
    子类可以覆盖该方法以实现资源清理工作，GC在回收对象之前调用该方法
    finalize方法，若未覆盖，则直接将其回收
    否则，若对象未执行过finalize方法，将其放入F-Queue队列，由一低优先级线程执行该队列中对象的finalize方法
    执行finalize方法完毕后，GC会再次判断该对象是否可达，若不可达，则进行回收
    不建议用finalize方法完成“非内存资源”的清理工作，但建议用于：
        清理本地对象（通过JNI创建的对象)
        作为确保某些非内存资源（如Socket、文件等）释放的一个补充
        在finalize方法中显式调用其他资源释放方法

垃圾回收器
    G1
        -XX:+UseG1GC
        由于这种方式的侧重点在于回收垃圾最大量的区间（Region），所以我们给G1一个名字：垃圾优先（GarbageFirst）
    CMS
        CMS：“标记-清除”算法、内存碎片、若干次GC后进行一次碎片整理
    ZGC

    Parallel GC
JVM选项规则
    java-version标准选项，任何版本JVM/任何平台都可以使用(如果 - 代表 标准选项任何版本都兼容不用考虑版本问题)
    java-Xms10m非标准选项，部分版本识别 (如果 -X 代表 部分版本识别)
    java-XX：+PrintGCDetails不稳定参数，不同JVM有差异，随时可能会被移除 (+代表开启/-代表关闭)
    1.8+优先使用G1收集器摆脱各种选项烦恼
    java-jar-XX:+UseG1GC-Xms2G-Xmx2G-Xss256k
    -XX:MaxGCPauseMillis=300-Xloggc:/logs/gc.log-XX:+PrintGCTimeStamps
    -XX:+PrintGCDetails test.jar
    -Xms与-Xmx设置相同，减少内存交换
    评估Xmx方法：第一次起始设置大一点，跟踪监控日志，调整为堆峰值*2～3即可
    最多300毫秒STW时间
    200~500区间，增大可减少GC次数，提高吞吐
    -Xss128k/256k虚拟机栈空间一般128K就够用了
    超过256k考虑优化不建议超过 256k
    G1一般不设置新生代的大小G1新生代是动态调整的

JVM 命令
    jps 查看正在运行JAVA进程信息
    jstat -gcutil 进程号 1000 10 (监控该进程占用了那些空间 每块进程资源占用的详情打印)
    jmap -dump 生成dump文件 查看详情信息
    VisualVM
        -XX:+HeapDumpOnOutOfMemoryError (在程序OOM时候 自动 dump 日志信息)
        查看有多少类
        查看有多少类实例对象
        堆 类资源数量排列排序展示
        堆 类资源所占内存大小排列排序展示
        可以查看 GC ROOT 查看实际类资源创建链条排查
        Select in Threads 查看线程详情信息

Arthas