索引：
    创建索引
        PUT /es_index
    查询索引
        GET /es_index
        返回响应：
            别名 “aliases”： {}
            映射 “mappings”： {}
            settings {} 属性:
                索引名称 "provided_name": ""
                分片 "number_of_shards": ""
                    将一个物理大索引拆分成若干个小索引每一个小索引称为一个Shard
                    Index是逻辑概念，底层是若干个Shards 分布在若干节点上
                    个Shard最多可存放20亿个文档
                    路由算法（索引和查询）
                    shard number = hash(document id) % number_of_primary_shards
                    为了分担服务器压力 提供读写吞吐量 采用分片方式进行存储
                    es集群主分片数量一旦确定不可改变
                    一个文档只能存储在一个主分片不能被分散存储
                    主分片数量确定了你的存储容量
                    查看:
                        GET /_cat/indices?v
                    设置参考
                        视情况定：节点数量 每个节点的容量 索引数量/大小 查询模式
                        业界推荐单个shard<=50GB
                        Github实践128个shards，每个120GB
                        作者推荐25G～40GB（考虑堆内存需求）
                        500GB数据->10~20个Shards
                        推荐每GB堆内存支持最多20个Shards
                        设置jvm.options（Xms/Xmx），ES缺省1GB
                        3 Shards+3Replicas/Shard，每个Shard50GB
                        Shards存储需求3x50GB=150GB
                        Replicas存储需求3x3x50GB=450GB
                        日志类应用 单个分片不要大于50GB
                        搜索类应用 单个分片不要超过20GB
                        索引分片数为数据节点的倍数

                        数据规模
                        数据增量
                        服务器配置
                        每一个G堆内存：支持20-25个分片
                            elasticsearch堆内存设置：30G设置30堆内存大小：单机节点支持600-750个分片

                    按需将索引的分片分配到特定的节点：
                    分片设置过大 过多有什么问题
                        分片数据迁移耗时过长
                        节点间数据均衡耗时较长
                        过多的分片会导致资源竞争
                        降低查询性能
                        导致数据分布不均
                        如果不能及时掌控业务变化，可能经常遇到单分片记录超限、写入拒绝等问题‌


                副本 "numberofreplicas": ""
                    副本是分片的完全拷贝 也称replica shards
                    被复制的源Shard称为PrimaryShard
                    Primary Shard + Replica Shards统称Replication Group
                    查看
                        GET / cat/shards?v
                        GET / cluster/health
                    设置参考
                        副本是主分片的拷贝
                        副本会降低数据的索引速度：有几份副本就会有几倍的CPU资源消耗在索引I上
                        会减缓对主分片的查询压力 但是会消耗同样的内存资源
                        如果机器资源充分 提高副本数 可以提高整体的查询QPS
                        关键业务：
                            2+
                        非关键业务：
                            1
                        auto_expand_replicas
                    快照：
                        快照用于对某个索引或者对整个集群进行备份
                uuid "uuid": ""
                版本 "version": {}

                creation_date: "时间戳"
                分词器：
                    "index"：{
                        "analysis.analyzer.default.type"： "ik_max_word"
                    }
                    内置：
                        Standard Analyzer 一默认分词器 按词切分 小写处理
                        Simple Analyzer －按照非字母切分（符号被过滤） 小写处理
                        Stop Analyzer －小写处理 停用词过滤 (the, a, is)
                        Whitespace Analyzer 一按照空格切分 不转小写
                        Keyword Analyzer －不分词 直接将输入当作输出
                        Patter Analyzer 一正则表达式 默认\W+(非字符分隔）
                        Customer Analyzer 自定义分词器
    索引刷新 refresh
        refresh=true（或refresh）立即refresh文档可立即查询到
        refresh=wait_for 阻塞client直到设置的refresh-interval

        PUT es_index/_doc/1?refresh
        PUT es_index/_doc/1?refresh=true
        PUT es_index/_doc/1?refresh=false
        PUT es_index/_doc/1?refresh=wait_for

        PUT /es_index/_settings
        {
            "index": {
                "refresh_interval": "15s"
            }
        }

    Shard allocation awareness:

    Force awareness：

    SegmentFiles的数量：数量愈多对查询的速度与磁碟的空间愈不好
    Shard的数量：愈多对Indexing的速度愈好 但对查成本较高 单一Shard愈大对Cluster 的 Rebalance 的成本愈高
    Index的大小：愈大对于查询效率愈好 以Time-based资料来看的话 影响的是资料移转到下一个段的等待时间
    资料的新旧程度：新的资料通常使用频率较频繁 会给较好的硬体资源 较旧的资料较少使用 可配置较差的硬件资源
    时间粒度：当资料量很大时 在观察过往的资料往往时间粒度会抓较大 且观察的结果（例如：每天的log数量 每天的总销售金额 每天每部影片各别的观看次数...等）
    Index愈来愈多：资源总是有限，太旧的资料会面删除，可保留囊的结果
    资料的安全性：除了存取控制要妥善的限制之外 资料的备份也是非常重要的机制

    re-indexing 索引重建
        索引的Mappings发生变更：字段类型更改 分词器及字典更新
        索引的Settings发生变更：索引的主分片数发生改变
        集群内 集群间需要做数据迁移
        Update By Query: 在现有索引上重建
        Reindex：在其他索引上重建索引
    查看 Node 详情
        GET _cat/nodes
    索引是否存在
        HEAD /es_index
    删除索引
        DELETE /es_index
    关闭索引
        POST /es_index/close
    打开索引
        POST /es_index/_open
    重建索引
        POST _reindex
    查看索引
        GET /es_index/_settings
    显示索引状态为 green 的索引
        GET /_cat/indices?v&health=green
    按照文档个数排序
        GET /_cat/indices?v&s=docs.count:desc
    查看每个索引占用的内存信息
        GET /_cat/indices?v&h=i,tm&s=tm:desc

    扩容
        横向扩容
            如果数据量越来越大只能增加主分片的数量（但是：主分片数量一旦设定，无法更改）
            解决方案：
                重新创建一个索引库设置与预期的分片数量相同的分片迁移索引|数据即可

        继续扩容
    故障转移

    数据恢复

    故障探查

    脑裂

文档：
    元数据:
        "_index" 文档所属的索引名
        "_type" 文档所属的类型名
        "_id" 文档唯一ID
        "_source" 文档的原始JSON数据
        "_version" 文档的版本信息
        "_score" 相关性打分
    添加文档：
        指定 ID：
            PUT /es_index/_doc/1
        自生成ID：
            POST /es_index/_doc
        共同点： 底层是先做删除后更新 形成一种覆盖的形式
        基于文档ID判断后添加 (保证文档唯一性)：
            PUT /es_index/create/1
            POST /es_index/create/1
        批量添加：
            创建 底层要基于文档ID校验： (如果文档存在则抛出异常)
                POST _bulk
                {
                    "create": {
                        "_index": "xxx对应索引",
                        "_type": "_doc",
                        "_id": xxx
                    }
                }
                {
                    "id":xxx,
                    添加数据....
                }
            创建 如文档存在覆盖原来文档：
                POST _bulk
                {
                    "index": {
                        "_index": "xxx对应索引",
                        "_type": "_doc",
                        "_id": xxx
                    }
                }
                {
                    "id":xxx,
                    添加数据....
                }

    更新文档：

        指定 ID：
            POST /es_index/_update/1
            {
                "doc": {
                    更新文档的数据....
                },
                "doc_as_upsert": true # 如果该文档不存在则创建反之更新文档
            }

        基于查询条件更新： (类似于 Mysql Update xxx where xxx=xx )
            1 存储生成快照 -> 2 Search Query Replication Group -> 3 Bulk Update
            基于乐观锁概念 比较并判断 version_conflicts 字段 (是否有版本冲突)
            POST /es_index/_update_by_query
            {
                "query": {
                    "match":{
                        "_id": xx
                    }
                },
                "script": {
                    "source": "ctx._source.age = 30"
                },
                "conflicts": "proceed" # 当遇到快照冲突后续如何操作 proceed 继续执行  中止执行
            }

        upsert 更新:
            POST /es_index/_update/1
            {
                "upsert": {
                    更新数据....
                }
            }



    查询文档：
            Response 响应：
                took： 花费时间
                total: 符合条件的总文档数
                hits： 结果集
            全文挡查询：
                GET /es_index/_search
            基于ID查询：
                GET /es_index/_doc/1

            match (全文检索)：
                要 分词 算分
                如果目标字段是 text 类型则该字段在索引时也会被分词
                因此 match 查询可以与分词后的词条进行匹配适用于全文检索场景
                会对查询字符串进行分词处理并尝试匹配分词后的词条
                如果目标字段是 keyword 类型，则该字段在索引时不会被分词而是作为一个完整的值存储
                match 查询仍然会尝试匹配，但由于 keyword 字段未分词只有当查询字符串完全匹配字段值时才会返回结果
                支持 OR 和 AND 逻辑
                条件查询 or
                    GET /es_index/_search
                    {
                        "query":{
                            "match": {
                                "xxx字段": "xxx"
                            }
                        }
                    }

                条件查询 and
                    GET /es_index/_search
                    {
                        "query":{
                            "match": {
                                "xxx字段": {
                                    "query":  "xxx字段值",
                                    "operator": "and"
                                }
                            }
                        }
                    }

                查询条件 至少匹配(几个)
                    GET /es_index/_search
                    {
                        "query":{
                            "match": {
                                "xxx字段": {
                                    "query": "xxx字段值",
                                    "minimum_should_match": 2 至少匹配几个
                                }
                            }
                        }
                    }

                match_phrase 短语匹配 (对比 AND 更加精确 要求查询的分词与结果是连续的)：
                    GET /es_index/_search
                    {
                        "query":{
                            "match_phrase": {
                                "xxx字段": {
                                    "query": "xxx字段值" # 要求查询的分词与结果是连续的 (查询条件是什么查询结果就是什么)
                                    "slop": 2 # 指定中间可以隔多少个字符
                                }
                            }
                        }
                    }

                多条件字段查询:
                    GET /es_index/_search
                    {
                        "query":{
                            "multi_match": {
                                "query": "xxx字段值",
                                "fields": [
                                    "xxx条件字段",
                                    "xxx条件字段"
                                    ...
                                ]
                            }
                        }
                    }

                指定拼接查询条件查询 query_string:
                                允许我们在单个查询字符串中指定AND丨OR丨NOT条件同时也和multi_matchquery一样支持多字段搜索。
                                和match类似但是 match需要指定字段名query_string是在所有字段中搜索范围更广泛。
                                注意：查询字段分词就将查询条件分词查询查询字段不分词将查询条件不分词查询

                                指定单个查询字段范围：
                                    POST /es_index/_search
                                    {
                                        "query":{
                                            "query_string": {
                                                "default_field": "xxx字段" #指定字段查询范围 只搜索这个字段匹配的
                                                "query": "xxx字段值 AND xxx字段值"
                                            }
                                        }
                                    }
                指定多个查询字段范围：
                    POST /es_index/_search
                    {
                        "query":{
                            "query_string": {
                                "fields": [
                                "xxx字段", #指定字段查询范围 只搜索这个字段匹配的
                                "xxx字段"
                                ...
                                ]
                                "query": "xxx字段值 AND xxx字段值"
                            }
                        }
                    }

                简化 指定多个查询字段范围：
                    POST /es_index/_search
                    {
                        "query":{
                            "simple_query_string": {
                                "fields": [
                                "xxx字段", #指定字段查询范围 只搜索这个字段匹配的
                                "xxx字段"
                                ...
                                ]
                                "query": "xxx字段值",
                                default_operator: "AND" # 比较符号
                            }
                        }
                    }

                指定返回值:
                    GET /es_index/_search
                    {
                        "query":{
                            "match_all": {},
                            "_source": [
                                "字段名称",
                                ...
                            ]
                        }
                    }
                    只看 source 字段里内容：
                        GET /es_index/_source/1
                    只看 元数据 内容:
                        GET /es_index/_doc/1?_source=false

            term：
            不分词 不算分
                精确查询 (如不进行分词)：
                    GET /es_index/_search
                    {
                        "query":{
                            "term": {
                                "FIELD": {
                                    "value": "xxx"
                                }
                            }
                        }
                    }
                精确查询 term
                查询字段映射类型为keyword
                    基于Query：
                        GET /es_index/_search
                        {
                            "query":{
                                "term": {
                                    "xxx字段.keyword": {
                                        "value": "xxx字段值"
                                    }
                                }
                            }
                        }
                    term 多值匹配
                        GET /es_index/_search
                        {
                            "query":{
                                "terms": {
                                    "xxx字段.keyword": [
                                        "xxx字段值"
                                            ...
                                        ]
                                    }
                                }
                            }
                        }

                    term 与 filter
                        跳过评分计算：避免 TF-IDF/BM25 等评分算法的计算，节省 CPU 和内存资源
                        term
                            term 查询：不支持直接的 OR 和 AND 逻辑，只能精确匹配单个值
                            term 查询不会对查询的词条进行分词
                            精确匹配字段的完整值 需计算评分根据匹配程度排序
                            适用于需要相关性排序的场景（如搜索关键词）
                            精确匹配非文本字段（如数字、枚举值）
                            直接匹配字段的原始值（未经分词处理）
                            对 text 类型字段需使用 .keyword 子字段（如 field.keyword）
                        filter
                            使用 bool 查询结合 filter 子句，灵活实现 OR 和 AND 逻辑
                            仅判断文档是否匹配条件
                            不计算相关性评分
                            结果可被缓存（重复查询时直接复用缓存，性能更优） 注意： 动态条件且无法缓存（如每次查询参数不同）
                            适用于 精确值筛选 高频重复查询 仅需筛选文档（如状态过滤、范围过滤）多条件组合
                            固定排序：当结合 sort 参数时，过滤结果按指定字段排序（如按时间倒序），不受评分干扰
                            聚合优化：在聚合（Aggregation）中使用过滤条件时，避免不必要的评分计算


                    range 范围查找
                        range检索是Elasticsearch中一种针对指定字段值在给定范围内的文档的检索类型
                        这种查询适合对数字日期或其他可排序数据类型的字段进行范围筛选
                        range检索支持多种比较操作符，如大于(gt)、大于等于(gte)、小于(It)和小于等于(lte)等，可以实现灵活的区间查询

                        Elasticsearch支持日期数学表达式，允许在查询和聚合中使用相对时间点。以下是一些常见的日期数学表达式的示例和解释
                        now：当前时间点
                        now-1d：从当前时间点向前推1天的时间点
                        now-1w：从当前时间点向前推1周的时间点
                        now-1M：从当前时间点向前推1个月的时间点
                        now-1y：从当前时间点向前推1年的时间点
                        now+1h：从当前时间点向后推1小时的时间点

                        GET /es_index/_search
                        {
                            "query":{
                                "range": {
                                    "xxx字段": {
                                        "get": 25, # 大于等于
                                        "lte": 25, # 小于等于
                                        "lt": 25,  # 小于
                                        "gt": 25,  # 大于
                                        }
                                    }
                                }
                            }
                        }

                    exists 检查特定字段是否存在
                        GET /es_index/_search
                        {
                            "query":{
                                "exists": {
                                    "field": "xxx字段"
                                    }
                                }
                            }
                        }

                    基于多个ID查询
                        GET /es_index/_search
                        {
                            "query":{
                                "ids": {
                                    "values": [
                                            id,
                                            ...
                                        ]
                                    }
                                }
                            }
                        }

                    基于 constant_score：
                        通过constantscore转成filtering 没有算分
                        GET /es_index/_search
                        {
                            "query":{
                                "constant_score": {
                                    "filter": {
                                        "term": {
                                            "xxx字段.keyword": "xxx字段值"
                                        }
                                    }
                                }
                            }
                        }
                前缀搜索 prefix:
                prefix会对分词后的term进行前缀搜索
                它不会对要搜索的字符串分词传入的前缀就是想要查找的前缀
                默认状态下前缀查询不做相关性分数计算它只是将所有匹配的文档返回然后赋予所有相关分数值为1
                它不会分析要搜索字符串传入的前缀就是想要查找的前缀
                默认状态下前缀查询不做相关度分数计算它只是将所有匹配的文档返回然后赋予所有相关分数值为1。
                它的行为更像是一个过滤器而不是查询。
                两者实际的区别就是过滤器是可以被缓存的而前缀查询不行。
                需要遍历所有倒排索引并比较每个词项是否以所搜索的前缀开头
                    GET /es_index/_search
                    {
                        "query":{
                            "prefix": {
                                "xxx字段.keyword": {
                                    "value": "xxx字段值"
                                }
                            }
                        }
                    }

                通配符查询 wildcard
                通配符查询可能会导致较高的计算负担因此在实际应用中应谨慎使用尤其是在涉及大量文档的情况下
                    GET /es_index/_search
                    {
                        "query":{
                            "wildcard": {
                                "xxx字段": {
                                    "value": "*xxx字段值*" # 如 *白*
                                }
                            }
                        }
                    }

                错误模糊冗余搜索 fuzzy
                    GET /es_index/_search -XP0ST http://localhost:9200/_bulk --data-binary "@bulk_data.json.txt"
                    {
                        "query":{
                            "fuzzy": {
                                "xxx字段": {
                                    "value": "*xxx字段值"
                                    "fuzziness"： 2 # 冗余错误数量 AUTO
                                }
                            }
                        }
                    }

                terms_set 多值基于条件个数精确匹配
                    GET /es_index/_search
                    {
                        "query":{
                            "terms_set": {
                                "xxx字段": {
                                    "terms": [
                                        xxx字段值,
                                        ...
                                    ],
                                    "minimum_should_match_script"： {
                                        "source": "2" # 条件个数
                                    }
                                }
                            }
                        }
                    }

            批量查询：
            curl -H "Content-Type: application/x-ndjson"
                基于ID与不同索引查询：
                    GET _mget
                    {
                        "docs":[
                            {
                                "_index": "索引名称",
                                "_id": xxx
                            }
                            ...
                        ]
                    }

                基于多条件与不同索引查询：
                    GET /_msearch
                    {
                        "index": "xxx"
                    }
                    {
                        "query": {
                            "match_all": {}
                        },
                        "size": xxx,
                        "from": 0
                    }

            布尔查询 bool Query:
                一个bool查询是一个或者多个查询子句的组合总共包括4种子句其中2种会影响算分2种不影响算分
                must:相当于&&必须匹配贡献算分 must:相当于&& 必须匹配 贡献算分 (内容合并)
                    可包含多个查询条件每个条件均满足的文档才能被搜索到每次查询需要计算相关度得分属于搜索上下文
                    must：各个条件都必须满足 所有条件是and的关系
                should:相当于|丨选择性匹配贡献算分 should:相当于! 选择性匹配 贡献算分 (内容合并)
                    可包含多个查询条件不存在must和fiter条件时至少要满足多个查询条件中的一个文档才能被搜索到否则
                    需满足的条件数量不受限制，匹配到的查询越多相关度越高，也属于搜索上下文
                    shouLd：各个条件有一个满足即可 即各条件是or的关系
                must_not:相当于！必须不能匹配不贡献算分 must_not:相当于！ 必须不能匹配 不贡献算分
                    可包含多个过滤条件每个条件均满足的文档才能被搜索到每个过滤条件不计算相关度得分结果在一定条件下会被缓存属于过滤上下文
                    must_not：不满足所有条件 即各条件是not的关系
                filter:必须匹配不贡献算法 filter：必须匹配 不贡献算法
                    filter：与must效果等同 但是它不计算文档得分效率更高点
                    可包含多个过滤条件每个条件均不满足的文档才能被搜索到每个过滤条件不计算相关度得分结果在一定条件下会被缓存属于过滤上下文
                QueryContext:相关性算分
                FilterContext:不需要算分（Yes|No）,可以利用Cache获得更好的性能
                相关性并不只是全文本检索的专利也适用于yes丨no的子句匹配的子句越多相关性评分越高
                如果多条查询子句被合并为一条复合查询语句比如bool查询则每个查询子句计算得出的评分会被合并到总的相关性评分中

                布尔查询可以按照布尔逻辑条件组织多条查询语句只有符合整个布尔条件的文档才会被搜索出来

                搜索上下文(querycontext)：使用搜索上下文时Elasticsearch需要计算每个文档与搜索条件的相关度得分这个得分的计算
                需使用一套复杂的计算公式，有一定的性能开销，带文本分析的全文检索的查询语句很适合放在搜索上下文中

                过滤上下文（filtercontext)：使用过滤上下文时，Elasticsearch只需要判断搜索条件跟文档数据是否匹配，例如使用Term query判断一个值是否跟搜索内容一致
                使用Range query判断某数据是否位于某个区间等。
                过滤上下文的查询不需要进行相关度得分计算还可以使用缓存加快响应速度很多术语级查询语句都适合放在过滤上下文中
                自定义控制查询权重
                    negative_boost
                    negative_Boost对negative部分query生效
                    计算评分时,boosting部分评分不修改 negative部分query乘以negative_boost值
                    negative_boost取值:0-1.0,举例:0.3
                    GET /es_index/_search
                    {
                        "query": {
                            "boosting": {
                                # 关心的查询
                                "positive": {
                                    "match": {
                                        "要查询的字段名"： "查询的值"
                                    }
                                }
                            },
                            "negative"： {
                                # 不关心的查询
                                "match": {
                                    "要查询的字段名"： "查询的值"
                                }
                            },
                            "negative_boost": 权重值
                        }
                    }

                    boost：

            分页查询:
                pageNo 第几页开始
                pageSize 每页显示多少条数据
                from 下一次开始的索引数 (pageNo - 1) * pageSize
                size 显示的数据数量
                10000以内:
                    GET /es_index/_search
                    {
                        "query":{
                            "match_all": {},
                            "size": xxx,
                            "from": 0
                        }
                    }
                设置修改条数限制：
                    PUT /es_index/_settings
                    {
                        "index.max_result_window":"20000"
                    }
                快照 Scroll：
                    查询命令中新增scro11=1m说明采用游标查询保持游标查询窗口一分钟。
                    这里由于测试数据量不够所以size值设置为2
                    实际使用中为了减少游标查询的次数可以将值适当增大比如设置为1000
                    GET /es_index/_search?scroll=1m
                    {
                        "query": {
                            "match_all": {}
                        },
                        "size": xxx
                    }

                    scroll_id的值就是上一个请求中返回的_scroll_id的值
                    GET /_search/scroll
                    {
                        "scroll": "1m",
                        "scroll_id": "xxxx"
                    }
                search_after
                第一步搜索需要指定 sort 并且保证值是唯一的(可以通过加入 id 保证唯一性)
                然后使用上一次 最后一个文档的 sort值进行查询
                GET /es_index/_search
                {
                    "size": 1,
                    "query": {
                        "match_all": {}
                    },
                    "search_after":[13,"上一次随机ID"],
                    "sort": [
                        {"_id","asc"}
                    ]

                }
                排序：
                Elasticsearch默认会以文档的相关度算分进行排序
                当指定了排序字段 Elasticsearch 就不会进行算分
                    GET /es_index/_search
                    {
                        "query":{
                            "match_all": {},
                            "sort": [
                                {
                                    "字段名称": "desc"
                                }
                            ]
                        }
                    }

    分词器：
        POST _analyze
        {
            "analyzer": "ik_max_word",
            "text": "值"
        }

        GET /_analyze
        {
            "analyzer": "分词器",
            "text": "要分词的文本"
        }

        POST _analyze
        {
            "field": "指定的字段",
            "analyzer": "ik_max_word",
            "text": "值"
        }
    删除文档：
        基于ID删除:
            DELETE /es_index/_doc/1
        基于查询删除:
            POST es_index/_delete_by_query
            {
                "query": {
                    查询匹配条件
                }
            }
    跨集群搜索:


别名:
    场景:
        跨多个索引数据统计
    POST /_aliases
    {
        "actions": [
            {
                "add": {
                    "index": "es_index",
                    "alias": "别名名称"
                }
            }
            ...
        ]
    }

相关性
    TF-IDF：
        TF是词频(Term Frequency)
            检索词在文档中出现的频率越高 相关性也越高。
        IDF是逆向文本频率(InverseDocumentFrequency)
            每个检索词在索引中出现的频率 频率越高 相关性越低。
        字段长度归一值（field-lengthnorm）
            字段的长度是多少？字段越短 字段的权重越高。
            检索词出现在一个内容短的title要比同样的词出现在一个内容长的 content 字段权重更大。I
            以上三个因素
                词频（termfrequency）
                逆向文档频率（inversedocumentfrequency）
                字段长度归一值（field-length norm）
                是在索引l时计算并存储的最后将它们结合在一起计算单个词在特定文档中的权重。
    BM25

索引模板：
    使用 索引创建设置组件化 基于索引模板前缀匹配,实现复用通用 索引 的 settings mappings
    索引模版只适用于新创建的索引

    静态模板
        template_
    动态模板
        dynamic_templates


Mapping 映射
    字段的多重映射
        (multi-fields）来实现同一个字段既能支持精确查询（不分词），又能支持分词查询
        在创建索引时，为字段设置 multi-fields，其中：
            主字段使用 text 类型，支持分词查询。
            子字段使用 keyword 类型，支持精确查询
    参数
        index
            是否对创建对当前字段创建倒排索引
            默认true，如果不创建索引该字段不会通过索引被搜索到
            但是仍然会在source元数据中展示
        analyzer
            指定分析器（characterfilter、tokenizer、Tokenfilters）
        boost:
            对当前字段相关度的评分权重，默认1
        coerce
            是否允许强制类型转换 true “1” => 1 false “1” =< 1
        copy_to
            该参数允许将多个字段的值复制到组字段中，然后可以将其作为单个字段进行查询
        doc_values
            为了提升排序和聚合效率，默认true
            如果确定不需要对字段进行排序或聚合
            也不需要通过脚本访问字段值
            则可以禁用doc值以节省磁盘空间（不支持 text 和 annotated_text ）
        eager_global_ordinals
            用于聚合的字段上，优化聚合性能
        Frozen indices（冻结索引）
            有些索引使用率很高
            会被保存在内存中
            有些使用率特别低宁愿在使用的时候重新创建
            在使用完毕后丢弃数据，Frozen indices 的数据命中频率小
            不适用于高搜索负载数据不会被保存在内存中
            堆空间占用比普通索引少得多 Frozen indices 是只读的
            请求可能是秒级或者分钟级
            *eager_global_ordinals 不适用于 Frozen indices
        enable
            是否创建倒排索引
            可以对字段操作也可以对索引操作
            如果不创建索引
            让然可以检索并在_source元数据中展示
            谨慎使用，该状态无法修改
            fielddata：查询时内存数据结构
            在首次用当前字段聚合
            排序或者在脚本中使用时
            需要字段为fielddata数据结构
            并且创建倒排索引保存到堆中
        ignore_above
            超过长度将被忽略
        index_options
            控制将哪些信息添加到反向索引引中以进行搜索和突出显示 仅用于text字段
        Index_prefixes 前缀搜索
            minchars
                前缀最小长度，>0，默认2（包含）
            max_chars
                前缀最大长度，<20，默认5（包含）
        norms
            是否禁用评分（在filter和聚合字段上应该禁用）
        nullvalue
            为null值设置默认值**
        store
            设置字段是否仅查询
        similarity
            为字段设置相关度算法，支持BM25、claassic（TF-IDF）、boolean

    查看:
        GET /es_index/_mapping
    显示设置
        PUT es_index
        {
            "mappings": {
                "properties": {
                    "xxx字段"： {
                        "type": "constant_keyword",
                        "value": "xxx字段值"
                    }
                }
            }
        }
        PUT es_index
        {
            "mappings": {
                "properties": {
                    "xxx字段"： {
                        "type": "字段类型"
                        "index": false # Index－控制当前字段是否被索引 默认为true 如果设置成 false 该字段不可被搜索
                    }
                }
            }
        }
        index_options:
            四种不同级别的IndexOptions配置 可以控制倒排索引l记录的内容 记录内容越多 占用存储空间越大
            docs － 记录 doc id
            freqs － 记录 doc id 和 term frequencies
            positions - 记录 doc id / term frequencies / term position
            offsets - doc id / term frequencies / term posistion / character offects
            Text 类型默认记录postions，其他默认为docs
        需要对Null值实现搜索:
            只有Keyword类型支持设定Null_Value
            PUT es_index
            {
                "mappings": {
                    "properties": {
                        "xxx字段"： {
                            "type": "Keyword"
                            "null_value" "NULL"
                        }
                    }
                }
            }
        copy_to:
            copy_to将字段的数值拷贝到目标字段
            PUT es_index
            {
                "mappings": {
                    "properties": {
                        "firstName"： {
                            "type": "text"
                            "copy_to" "fullName"
                        },
                        "lastName"： {
                            "type": "text"
                            "copy_to" "fullName"
                        }
                    }
                }
            }
            效果：
                GET users/_search?q=fullName:(Ruan Yiming)

    类型
        boolean
        float 小数点
        date "format" : "yyyy/MM/dd HH:mm:ss yyyy/MM/dd epoch_millis"
        long 表示数值
        integer 表示数值
        double 表示浮点数
        alias 为现有字段定义别名
        binary
        join 为同一索引中的文档定义父/子关系
        object 用于单个JSON对象
        nested 表示一个对象数组
            如果实体类中存在集合类型的属性
            那么此时就需要将该属性的类型设置为Nested类型
            如果不设置为Nested类型ES会对该属性进行扁平化处理一旦进行了扁平化处理那么此时在搜索的时候就会出现问题
        Keyword 对值的准确匹配主要用于准确匹配/过滤/聚合/排序 不分词
            用于id 枚举及不需要分词的文本 例如电话号码 email地址 手机号码 邮政编码 性别等
            适用于 Filter (精确匹配） Sorting 和 Aggregations
                constant_keyword
                wildcard
        text 表示文本信息 字符串值 无结构数据
            用于全文本字段 文本会被Analyzer分词
            默认不支持聚合分析及排序 需要设置fielddata为true
            默认会为文本类型设置成text 并且设置一个keyword的子字段
            如不需要检索 排序和聚合分析 Enable设置成false
            如不需要排序或者聚合分析功能
            Doc_values/fielddata设置成false
            如不需要检索 Index设置成false
            对需要检索的字段 可以通过如下配置 设定存储粒度
            Index_options / Norms ： 不需要归一化数据时 可以关闭
            更新频繁 聚合查询频繁的keyword类型的字段
            推荐将 eager alobal ordinals设置为 true
                search_as_you_type
                match_only_text
                completion
                token_count
                etc
        geo_point 纬度/经度积分
        geo_shape 用于多边形等复杂形状
        percolator
multi-fields
    通过 multi-fields 设置
    可以轻松实现同一个字段既能支持分词查询，又能支持精确查询。
    主字段使用 text 类型，子字段使用 keyword 类型
    查询时根据需要选择对应的字段即可。
聚合分析
    Bucket Aggregation 列满足特定条件的文档的集合
        类似于 GROUP by
    {
        "aggs": {
            "by_size":{
                "terms": {
                    "field": "要分组的字段"
                }
            }

        }
    }

    Metric Aggregation 数学运算，可以对文档字段进行统计分析
        类属于 COUNT() 等SQL统计函数
        SELECT MIN(price) MAX(price） FROM products
    {
        "aggs": {
            "自定义名称"： {
                "avg": {
                    "field"： "字段名称"
                }
            }
        }
    }

    Pipeline Aggregation 对其他的聚合结果进行二次聚合
    Matrix Aggregration 支持对多个字段的操作并提供一个结果矩阵
    {
        "size":0,
        "aggs": {
            "自定义别名"：{
                "max": {
                    "field": "字段名称"
                }
                ...
            }
        }
    }
    sub-aggregation



parent
child

优化
    写入：
        提高文档写入吞吐量
        过程：
            Refresh
                将文档先保存在 Index buffer 中
                以 refresh_interval 为间隔时间定期清空 buffer
                生成 segment, 借助文件系统缓存的特性
                先将segment 放在文件系统缓存中
                并开放查询 以提升搜索的实时性
            Translog
                Segment没有写入磁盘 即便发生了当机 重启后 数据也能恢复 默认配置是每次请求都会落盘
            Flush
                删除l旧的 translog 文件
                生成 Segment 并写入磁盘 /更新 commit point 并写入磁盘 ES 自动完成 可优化点不多
        客户端
            多线程
            批量写
        服务器
            降低IO操作
            使用ES自动生成的文档ld
            Refresh Interval
            降低 CPU和存储开销
            减少不必要分词
                只需要聚合不需要搜索 Index设置成false
                不需要算分 Norms 设置成 false
                不要对字符串使用默认的 dynamic mapping 字段数量过多 会对性能产生比较大的影响
                Index_options 控制在创建倒排索引|时 哪些内容会被添加到倒排索引中 优化这些设置 一定程度可以节约 CPU
                关闭_source 减少 IO 操作 （适合指标型数据）
            避免不需要的doc_values
            文档的字段尽量保证相同的顺序 可以提高文档的压缩率
            尽可能做到写入和分片的均衡负载 实现水平扩展
            Shard Filtering
            Write Load Balancer
            调整BuIk线程池和队列
                单个buk请求体的数据量不要太大 官方建议大约5-15mb
                写入端的bulk请求超时需要足够长 建议60s以上
                写入端尽量将数据轮询打到不同节点
                索引创建属于计算密集型任务
                应该使用固定大小的线程池来配置
                来不及处理的放入队列 线程数应该配置成 CPU 核心数 +1
                避免过多的上下文切换
            牺牲可靠性：将副本分片设置为0，写入完毕再调整回去
            牺牲搜索实时性：增加RefreshInterval的时间
            增大静态配置参数 indices.memory.index_buffer_size 默认是 10% 会导致自动触发 refresh
            Index.translog.durability：默认是request 每个请求都落盘 设置成 async 异步写入
            Index.translog.flush_threshod_size:默认 512 mb 可以适当调大 当 translog 超过该值 会触发 flush
            Index.translog.sync_interval 设置为 60s 每分钟执行一次
            牺牲搜索实时性：增加RefreshInterval的时间
            合理设置主分片数 确保均匀分配在所有数据节点上
            Index.routing.allocation.total_share_per_node:限定每个索引|在每个节点上可分配的主分片数
            5个节点的集群。索引有5个主分片，1个副本，应该如何设置?
            (5+5)/5=2
            生产环境中要适当调大这个数字 避免有节点下线时 分片无法正常迁移
            Index Alias 无需停机 无需修改程序 即可进行修改
Segment 段合并:
    优化点：降低最大分段大小 避免较大的分段继续参与Merge 节省系统资源 （最终会有多个分段）
    Index.merge.policy.segments_per_tier，默认为 10 越小需要越多的合并操作
    Index.merge.policy.max_merged_segment,默认5 GB 操作此大小以后，就不再参与后续的合并操作
Hot Warm Architecture
    数据通常不会有Update操作；适用于Timebased索引l数据（生命周期管理） 同时数据量比较大的场景。
    引入Warm节点，低配置大容量的机器存放老数据，以降低部署成本
    Hot 节点(通常使用 SSD）：索引I有不断有新文档写入。通常使用 SSD
    Warm 节点（通常使用 HDD）：索引|不存在新数据的写入；同时也不存在大量的数据查询
    Shard Filtering
        标记节点(Tagging)
            标记一个Hot节点
                bin/elasticsearch -E node.name=hotnode -E cluster.name=geektime -E path.data=hot_data -E node.attr.my_node_type=hot
            标记一个warm节点
                bin/elasticsearch -E node.name=warmnode -E cluster.name=geektime E path.data=warm_data -E node.attr.my_node_type=warm
            GET /_cat/nodeattrs?v
        配置索引到HotNode
            HotPhase：新的資料大量寫入HotNodes 要快 就配置较多的Primaryshards
            Rollover：随時間及資料量的成長 透過Rollover將Index進行rotate 產生新的Index來接新的資料 而原先的 Index會進入下一個Warm的段
        配置索引到Warm节点
            WarmPhase：進入到Warmdata 的段 會進入read-only 所以會透過ForceMerge與Shrink将Segment Files數量與Shards數量進行最佳化 也可同時配合Compress進行储存空間的優化
            ColdPhase：資料進入Codedata段 會將Index進行Freeze 以减少JVMheap的使用量 提供较高的延反應 但還是能即時使用的服務狀態
            Delete：再更久的資料，可再確已經被備份過之後進行刪除
        Rollup 可以 Hot,Warm,Cold 任何的Index当中把資料出 且以较大的 時間颗粒度進行總運算 將結果储存新的 Rollup Index中
        Rollup是定時執行 同時Rollup的資料在透過_rollup_search查询時 可混搭LiveData+RollupData 結果會自動合供去除掉重覆的 也因此當舊的資料被刪除後 存在Rollup的資料一樣能提供總後的查結果
        Cron Job + Batch => Aggregation (Date Histogram, Histogram, Terms, Metrics)
        Experimental 目前是立的功能，因此Rollup Index不能Rollover 未來會轉成為 ILM當中的一個Action
时间序列的索引
    按照时间进行划分索引 会使得管理更加简单。例如 完整删除一个索引 性能比 delete by query 好 定期关闭或者删除索引

与算分和分词相关的查询操作：
    match
        operator
        minimum_should_match_script
    match_phrase
    multi_match
    query_string
    simple_query_string

不使用算分和分词的查询操作：
结构化数据范围包括：
日期 布尔类型和数字都是结构化的
如彩色笔可以有离散的颜色集合：红(red)、绿(green、蓝(blue)
一个博客可能被标记了标签 例如，分布式(distributed)和搜索(search)
电商网站上的商品都有UPC（通用产品码UniversalProductCode）或其他的唯一
    term
        分词忽略大小写
        PUT es_index
        {
            "settings": {
                "analysis":{
                    "normalizer": {
                        "es_normalizer": {
                            "filer": [
                                "lowercase",
                                "asciifolding"
                            ],
                            "tyoe": "custom"
                        }
                    }
                }
            }
        }
    constant_score
    filter
        不会进行算分
        会使用查询缓存
    前缀查询 prefix
        默认状态下 前缀查询不做相关度分数计算
        它只是将所有匹配的文档返回 然后赋予所有相关分数值为1
        它的行为更像是一个过滤器而不是查询
        两者实际的区别就是过滤器是可以被缓存的 而前缀查询不行
        需要遍历所有倒排索引 并比较每个term是否已所指定的前缀开头 (有性能问题)
    通配符查询 wildcard
        工作原理和prefix相同 只不过它不是只比较开头，它能支持更为复杂的匹配模式
    范围查询 range
    日期 range date
    多id查询ids
    模糊查询 fuzzy

Transform
    將資料以Pivot的方式進行分析運算將結果存在獨立的Index中
    適合複雜的Aggregation的運算及報表的定期處理工作
    也可以這個機制查询的總結果建立成Index 當作Ingest处理時Enrich資料的LookupDataSource
    =>每月營銷報表、每月產品銷量分析、每日影片播放量

使用SnapshotLifecycleManagement（SLM）來管理資料的備份
    設定 定期 備份的保存時間及數量，確保備份所估用的空間不會無限增長

自动补全 completion
    CompletionSuggester实现自动补全功能
    需要自动补全的字段类型一定是 completion 参与补全查询的字段必须是completion类型
    字段的内容可以是用来补全的多个词条形成的数组
    用于自动补全查询的字段的类型必须是completion
    GET /es_index/_search
    {
        "suggest": {
            "suggester": {
                "prefix": "自动补全搜索的前缀词",
                "completion":{
                    field: "自动补全字段",
                    "skip_duplicates": true, # 去重
                    "size": 10 # 期望显示条数 (可选)
                }
            }
        }
    }

查询类型
    Query DSL
        全文检索
        Query String
            简单查询
            不依赖于特定客户端
        Fulltext Query
            全文检索
        Term Query
            精确查询
        Filter
            过滤器
        Bool Query
            组合查询
            minimum_should_match
                参数指定should返回的文档必须匹配的子句的数量或百分比
                如果bool查询包含至少一个should子句
                而没有must或filter子句
                则默认值为1 否则，默认值为0
    Script
        自定义可编程查询
    Aggregations
        数据分析
    SQL
        以SQL语音适配查询
    EQL 事件查询

写入原理
    segment
        每一个 倒排索引 创建都会生成 segment 文件
        .del File
        partial update
        delete
    refresh
        刷新以后数据 进入到 系统缓存此时才能提供页面查询
        可配置
        refresh 动作是在 JVM 里
    Commit Point
        基于配置 预值阈值 数据 segment 文件 提交到本地物理内存
        1：选择相似segment合并merge
        2:flush操作
        3：创建新的 commint point 标记新的 segment 删除旧的标记
        4:将新的segment搜索状态打开
        5：删除旧的segment文件
    OS Cache
        物理内存
    fsync
    Buffer
        写入的数据最先进入 Buffer 进行缓存排序
    translog
        类型于Mysql redo 日志 防止系统断电 内存数据丢失
        refresh 刷新时触发
        触发flush
            当文件大小达到國值或者一定时间 （默认30分钟）
            1:commit
            1:fsync
            2：清空translog
    尽量使用bulk批量写入
    增加flush时间间隔，目的是减小数据写入磁盘的频率，减小磁盘lO
    增加rfresh_interval的参数值，目的是减少segment文件的创建，减少segment的merge次数
        merge是发生在jvm中的，有可能导致fullGC，增加refresh会降低搜索的实时性。
    增加Buffer大小，本质也是减小refresh的时间间隔，因为导致segment文件创建的原因不仅有时间阈值
        还有buffer空间大小，写满了也会创建。默认最小值48MB<默认值堆空间的10%<默认最大无限制
    大批量的数据写入尽量挫制在低检索请求的时间段，大批量的写入请求越集中越好。
        第一是减小读写之间的资源抢占，读写分离
        第二，当检索请求数量很少的时候，可以减少甚至完全删除副本分片
        关闭segment的自动创建以达到高效利用内存的目的
        因为副本的存在会导致主从之间频繁的进行数据同步
        大大增加服务器的资源占用。
    Lucene的数据的fsync是发生在OScache的，要给OScache预留足够的内从大小，详见JvM调优。
    通用最小化算法，能用更小的字段类型就用更小的，keyword类型比int更快
    ignore_above：字段保留的长度，越小越好
    调整_source字段，通过include和exclude过滤
    store：开辟另一块存储空间，可以节省带宽
    禁用all字段
        al字段的包含所有字段分词后的Term，作用是可以在搜索时不指定特定字段，从所有字段中检索，ES6.0之前需要手动关闭
    关闭Norms字段
        计算评分用的，如果你确定当前字段将来不需要计算评分
        设置false可以节省大量的磁盘空间，有助于提升性能。
        常见的比如filter和agg字段，都可以设为关闭。
    关闭index_options（谨慎使用，高端操作）
        词设置用于在indextime过程中哪些内容会被添加到倒排索引l的文件中，例如TF，
        docCount、postion、offsets等
        减少option的选项可以减少在创建索引I时的cPU占用率
        不过在实际场景中很难确定业务是否会用到这些信息
        除非是在一开始就非常确定用不到否则不建议删除

搜索速度调优
    使用filter代替query
    避免深度分页，避免单页数据过大，可以参考百度或者淘宝的做法。
    es提供两种解决方案 scrollsearch 和 searchafter 注意关于 index type 的使用
    避免使用稀疏数据
    冷热分离的架构设计
    fielddata：搜索时正排索引，doc_value为indextime正排索引l
    enabled：是否创建倒排索引
    doc_values：正排索引，
    对于不需要聚合的字段，关闭正排索引|可节省资源，
    提高查询速度开启自适应副本选择（ARS），6.1版本支持，7.0默认开启，

节点类型
    master：主节点
        负责管理集群状态 分片状态 副本状态 节点得发现删除，只负责维护集群相关状态不负责对数据增删查改请求进行处理
    data：数据节点
    data_content：数据内容节点
    data_hot:热节点
    data_warm：索引|不再定期更新，但仍可查询
    data_code：冷节点，只读索引
    Ingest：预处理节点，作用类似于Logstash中的Filter ml：机器学习节点
    remote_cluster_client：候选客户端节点 transform：转换节点
    voting_only：仅投票节点