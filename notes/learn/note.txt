名词
    Broker(代理)
        消息中间件处理节点一个Kafka节点就是一个broker
        一个或者多个Broker可以组成一个Kafka集群
    Topic(主题)
        Kafka根据topic对消息进行归类
        发布到Kafka集群的每条消息都需要指定一个topic
    Partition(分区)
        物理上的概念
        一个topic可以分为多个partition每个partition内部是有序的
    Replica(副本)
        副本每个partion有多个副本存储在不同的broker上
        保证消息的高可用
    Segment(片段)
        partition物理上由多个segment组成每个Segment存着message信息
    Message(消息)
        消息是基本的通讯单位
        由一个key
        一个value和时间戳构成
    Producer(生产者)
        消息生产者向Broker发送消息的客户端
    Consumer(消费者)
        消息消费者从Broker读取消息的客户端
    ConsumerGroup(消费者群组）
        每个Consumer属于一个特定的ConsumerGroup
        一条消息可以发送到多个不同的 ConsumerGroup
        但是一个ConsumerGroup中只能有一个Consumer能够消费该消息
    AR
        kafka中所有副本统称AR（AssignedRepllicas）
        AR=ISR+OSR
    ISR
        一组与Topic分区的Leader保持同步的Follower 分区副本
        ISR列表中的副本会定期向Leader 同步数据，确保数据的一致性
        和leader保持同步的follower集合
        如果follower超过replica.lag.time.max.ms默认30s没有同步 则会被踢出isr
    OSR
        表示follower与leader副本同步时，延迟过多的副本
    LEO
        每个副本的最后一个offset
        LEO（lastendoffset）就是该副本底层日志文件上的数据的最大偏移量的下一个值
        当我知道了LEO为10 我就知道该日志文件已经保存了10条信息，位移范围为[0,9]
    HW
        所有副本中最小的LEO
        指的是消费者能见到的最大的offset，ISR队列中最小的LEO。
生产者
    发送并忘记(fire-and-forget)
        producer.send(record);
    同步发送
        producer.send(record).get();
    异步发送
        producer.send(record, new Callback(){});
        Kafka的Producer发送消息采用的是异步发送的方式。
        在消息发送的过程中，涉及到了
        两个线程
        main线程和Sender线程，以及一个线程共享变量
        RecordAccumulator.
        main线程 将消息发送给 RecordAccumulator
        Sender线程 不断从 RecordAccumulator 中拉取消息发送到 Kafka broker。

    拦截器
        org.apache.kafka.clients.producer.Producerlnterceptor
        Interceptor可能被运行在多个线程中 因此在具体实现时用户需要自行确保线程安全
        指定了多个lnterceptor 则Producer将按照指定顺序调用它们 并仅仅是捕获每个lnterceptor可能抛出的异常记录到错误日志中而非在向上传递
    序列化器
        key
            key序列化器 org.apache.kafka.common.serialization.Serializer
        value org.apache.kafka.common.serialization.Serializer
            value序列化器
    分区器
        如果在记录中指定了分区，则使用指定的分区
        如果没有指定分区，但是有key的值，则使用key值的散列值计算分区
        如果没有指定分区也没有key的值，则使用轮询的方式选择一个分区
        org.apache.kafka.clients.producer.Partitioner
    缓冲区

    流程
        主线程 -> 生产的消息 -> [ 拦截器 序列化器 分区器 ] -> 消息累加器 -> Sender线程 -> 创建Request -> 封装并缓存为 (node信息+要发送的消息数据请求信息) -> 基于 NIO Selector发生
        生产者消息记录 -> send() 函数 -> [ 拦截器 序列化器 分区器 ] -> 缓冲区 -> 达到batch.size 或到达linger.ms -> Brokers(基于分区策略到达分区) -> 分区 -> 给生产者 ACK 响应 -> 重试 -> 缓冲区

    ack
        0
            生产者不确认消息是否发送成功 只要把他放入socket缓冲区就认为消息已经发送
        1
            生产者发送消息后 只要到了leader就认为消息已经发送成功
        -1
            生产者发送消息后 不仅到了leader 并且 leader还同步给了其他follower才算是同步
            isr
                isr指的是与leader数据同步的follower分区
            osr
                osr指的是与leader数据不那么同步 或者说复制进度落下的follower分区
    Exactly Once
        At Least Once
            将服务器的ACK级别设置为-1，可以保证Producer到Server之间不会丢失数据 即 At Least Once
        At Most Once
            相对的，将服务器ACK级别设置为O，可以保证生产者每条消息只会被发送一次，即 At Most Once
        AtLeast Once + 幂等性 = ExactlyOnce
            0.11版本的Kafka，引入了一项重大特性：幂等性。
            所谓的幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条。
            幂等性结合AtLeastOnce语义就构成了Kafka的ExactlyOnce语义
            要启用幂等性，只需要将Producer的参数中 enable.idompotence 设置为true即可。
            Kafka 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。
            开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带SequenceNumber。而
            Broker端会对<PID,Partition,SeqNumber>做缓存，当具有相同主键的消息提交时，Broker只会持久化一条。
            但是PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的ExactlyOnce。
    事务
        Kafka从0.11版本开始引入了事务支持。
        事务可以保证Kafka在ExactlyOnce语义的基础上，生产和消费可以跨分区和会话
        要么全部成功，要么全部失败。
        Producer事务
            为了实现跨分区跨会话的事务，需要引入一个全局唯一的TransactionID，并将Producer
            获得的PID和TransactionID绑定。
            这样当Producer重启后就可以通过正在进行的Transaction ID 获得原来的PID。
            为了管理Transaction，Kafka引入了一个新的组件TransactionCoordinator。
            Producer就是通过和TransactionCoordinator交互获得TransactionID对应的任务状态。
            Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic
            这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。
        Consumer 事务
            上述事务机制主要是从Producer方面考虑，对于Consumer而言，事务的保证就会相对较弱，尤其时无法保证Commit的信息被精确消费。
            这是由于Consumer可以通过offset访问任意信息，而且不同的 SegmentFile生命周期不同
            同一事务的消息可能会出现重启后被删除的情况。

    消息收集器
        消息收集器RecoderAccumulator为每个分区都维护了一个 Deque<ProducerBatch>类型的双端队列
        ProducerBatch
            ProducerBatch可以理解为ProducerRecord的集合
        由于生产者客户端使用java.io.ByteBuffer在发送消息之前进行消息保存，并维护了一个BufferPool实现ByteBuffer的复用；
        该缓存池只针对特定大小（batch.size指定）的ByteBuffer进行管理，如果消息过大的缓存，不能做到重复利用。
        每进入一个ProducerRecord都会寻找自己的ProducerBatch
        如果能写入则写入已自己的ProducerBatch
        如果不能写入那就新建一个ProducerBatch
    compression
        开启压缩compression.type=snappy
        压缩格式
            none
            gzip
            snappy
            lz4

    retries 该值为一个大于1的值指的是发送消息失败后重新发送消息的次数但重试可能导致消息乱序
        retry.backoff.ms 每次重试之间等待的时间

    request.timeout.ms 客户端等待响应的最大时长 如果超时 就会重新发送，除非达到重试次数
    该设置应该比replica.lag.time.max.ms大 以免服务器延迟时间内重试

    linger
        默认情况下 linger.ms=0ms 即缓冲区buffer.memory里面一有数据就会立刻被传输到broker里面去
        适当将linger.ms=5~100ms调大则在linger.ms时间内缓冲区里面会有更多数据
        此时再从缓冲区中拉取数据
        每次拉取的batch.size可以填充更多的数据

    batch.size 批量发送的数据量
        需要配合 linger 每次从缓冲里面拉取可能不足batch.size=16k

    send.buffer.bytes 利用TCP发送数据的时候使用的缓冲区

    connections.max.idle.ms 当连接空闲时间达到这个值 就关闭连接

    buffer.memory
        配置buffer.memory缓冲区，默认大小32M，33554432

    如何重试仍然保证消息不乱序？
        max.in.flight.requests.per.connection为1
        在确认一批消息发送成功并且确认后 才会发送下一批消息 这样就可以保证顺序 但是严重影响吞吐量
    零拷贝
        传统拷贝
            从磁盘中读取目标文件内容拷贝到内核缓中区
            CPU空制器再把内核缓中区的数据赋值到用户空间的缓中区中
            接着在应用程序中：调用write方法
            把用户空间缓中区中的数据考贝到内核下的socket Buffer中。
            把在内核模式下的 SocketBuffer中的数据赋值到网卡缓中区
            网卡缓中区再把数据传输到目标服务器上
                2次可优化拷贝
                    从内核空间赋值到用户空间
                    从用户空间再次赋值到内核空间
                    造成上下文切换
        零拷贝
            把这两次多于的拷贝省略掉
            应用程序可以直接把
            磁盘中的数据从内核直接传送到Socket
            零拷贝通过DMA技术 把文件内容 复制到内核空间的ReadBuffer
            接着把包含数据位置和长度信息的文件描述符加载到Socket Buffer中
            DMA引擎直接把数据从内核空间传递给网卡设备
            减少 CPU的上下文切换
            在Java中, FileChannal.transferTo 方法的底层实现就是sendfile方法
        mmap文件映射机制
            原理：将磁盘文件映射到内存，用户通过修改内存就能修改磁盘文件。
            使用这种方式可以获取很大的/O提升
            省去了用户空间到内核空间复制的开销
    优化
        batch.size 64KB-1MB
            批次大小指的是生产者在将消息发送到KafkaBroker之前会将多条消息收集到一个批次中进行发送。
            增大批次大小可以显著减少网络请求次数，因为每次发送更多的消息，从而提高了网络传输的效率，有助于提升整体的吞吐量。
            然而，这也会带来一定的延迟，因为生产者需要等待更多的消息填满批次。
            如果批次一直无法填满，消息就会在生产者端停留更长时间，直到达到其他触发发送的条件。
            在高吞吐量且对延迟要求不是特别苛刻的场景下，可以适当增大该值。
        linger.ms 10 - 100ms
        max.in.flight.requests.per.connection
            该参数限制了单个连接上允许的最大未确认请求数。
            在Kafka中，生产者可以在一个连接上同时发送多个请求而无需等待每个请求的响应。
            如果将该值设置得过高，可能会导致消息的顺序被破坏。
            例如，当一个请求失败并重试时，后续已经发送的请求可能会先到达Broker，从而导致消息的顺序不一致。
            因此，需要根据实际情况合理设置该值，以平衡吞吐量和消息顺序性。
消费者
    反序列化
        org.apache.kafka.common.serialization.Deserializer<T>接口
    拦截器
        org.apache.kafka.clients.consumer.Consumerlnterceptor<K, V>接口
    消费组
        多个从同一个主题拉取消息的消费者可以被归于一个消费者组中
        消费组均衡地给消费者分配分区 每个分区只由消费组中一个消费者消费

        单一主题下分区与消费组的三种对应关系
            分区数量多于消费者

            分区数量等于消费者

            分区数量小于消费者

        auto.offset.reset
            earliest：自动重置偏移量到最早的偏移量
            latest：自动重置偏移量为最新的偏移量
            none：如果消费组原来的（previous) 偏移量不存在，则向消费者抛异常
            anything：向消费者抛异常

        enable.auto.commit
            如果设置为true消费者会自动周期性地向服务器提交偏移量
            重复消费问题
                Consumer每5s提交offset 自动提交逻辑 如 Offset没有提交则发生 重复消费问题
                假设提交offset后的3s发生了Rebalance
                Rebalance之后的所有Consumer从上一次提交的offset处继续消费
                因此Rebalance发生前3s的消息会被重复消费
            手动提交
                同步提交
                    同步提交只有在commitSync方法返回最新offset的时候才会认为成功 会影响TPS 方法会被阻塞
                异步提交
                    commitAsync出现问题不会自动重试 (需要手动处理)
        fetch.min.bytes 每次拉取消息的请求返回数据量的最小值
        fetch.max.wait.ms 如果数据量达不到拉取最小值的话 最多间隔如此长时间进行数据拉取
    负载均衡
        再平衡规定了一个消费组的所有消费者如何来分配订阅主题的每个分区
        rebalance 什么时候再均衡
            组成员发生变更 (新消费者加入消费组 有消费者主动离开消费组 有消费者下线离开消费组)
            消费者组的协调器节点发生了变更
            topic的分区数量的新增或者减少
            订阅主题数发生变更
            订阅主题的分区数发生变更
        再平衡
            再平衡规定了同一消费组所有消费者如何分配topic中的每一个分区
            再平衡时消费者无法消费消息：直到再平衡结束为止
                消费组内消费者数量发生变更
                主体内的分区数量发生变更
                订阅的主题发生变化
            重平衡过程中 Rebalance
                消费者无法从kafka消费消息
                这对kafka的TPS影响极大而如果kafka集内节点较多
                    比如数百个那重平衡可能会耗时极多数分钟到数小时都有可能
                    而这段时间kafka基本处于不可用状态
                    所以在实际环境中应该尽量避免重平衡发生
            避免
                不可能完全避免再平衡
                因为消费者岩机
                分区增加
                消费者增加
                主题增加
                要么是我们主动添加要么无法避免，因此我们要尽力避免kafka认为消费者故障这种情况的发生

                session.timout.ms控制消费者心跳超时时间
                    session.timout.ms：设置为6s
                heartbeat.interval.ms控制消费者心跳发送频率
                    heartbeat.interval.ms： 设置2s
                max.poll.interval.ms控制poll的间隔
                    max.poll.interval.ms：推荐为消费者处理消息最长耗时再加1分钟
            命令
                Heartbeat请求：consumer需要定期给组协调器发送心跳来表明自已还活着
                LeaveGroup请求：主动告诉组协调器我要离开消费组
                SyncGroup请求：消费组Leader把分配方案告诉组内所有成员
                    一旦完成分配 Leader会将这个方案封装进SyncGroup请求中发给消费组协调器
                    非Leader也会发SyncGroup请求
                    只是内容为空
                    消费组协调器接收到分配方案之后会把方案塞进SyncGroup的response中发给各个消费者
                JoinGroup请求：成员请求加入组
                    所有成员都向消费组协调器发送JoinGroup请求
                    请求加入消费组
                    一旦所有成员都发送了JoinGroup请求协调器从中选择一个消费者担任Leader的角色
                    并把组成员信息以及订阅信息发给Leader
                DescribeGroup请求：显示组的所有信息，包括成员信息，协议名称，分配方案，订阅信息等
            一旦协调器发现某个消费者挂了怎么办？
                一旦协调器认为某个消费者挂了那么它就会开启新一轮再均衡
                并且在当前其他消费者的心跳响应中添加"REBALANCEINPROGRESS"
                告诉其他消费者：重新分配分区。
    pull
        pull 模式不足之处是，如果kafka 没有数据，消费者可能会陷入循环中，一直返回空数据。
        针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，
        这段时长即为 timeout。
    poll
        poll：加入群组，接受分配到分区；轮询获取数据；发送心跳；自动提交
    close
        close：关闭网络连接；主动通知GroupCoordinator，自己已挂

    幂等性
    properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, "true");
        pid 每次重启kafka获得
        partition：分区号
        SeqNumber：自增号

    顺序消费
        kafka为什么会存在无序消费
            因为消费者是完全独立的一个网络节点
            所以可能会出现消息的消费顺序不是按照发送顺序来实现的
            从而导致消息的消费乱续的问题
            多分区生产消费速率不同导致 乱序
            单分区生产重试时导致 乱序
            当3失败后紧接看4成功了然后3 重试成功了这样数据就乱序了
        kafka如何保证有序消费
            自定义消息分区的一个路由算法
            批次排队实现顺序
                开启幂等性
                生产者在收到kafka响应之前可以投递多少个消息
                max.in.flight.requests.per.connection=1
            生产者在收到kafka响应之前可以投递多少个消息
            max.in.flight.requests.per.connection=5 retries>0允许重试
            会缓存5个数据，并保证5个数据内不会乱序(会在缓存过程中将消息进行排序)

    消息积压

    优化
        fetch.min.bytes 1M - 10MB

        fetch.max.wait.ms 500ms

        max.poll.records 500-5000

        auto.offset.reset earliest

Broker

    优化
        log.flush.interval.messages 1（立即刷盘，性能差)， n（批量刷盘，性能好，会丢数据）
        log.flush.interval.ms 1000-5000ms


消息的 推模式与拉模式
    push
        其实是基于消费端的长连接
        推模式可能在消费者不可达时
        大量消息积压再生产者端造成压力
    pull
        是消费者主动向Broker请求消息
        调整拉取间隔和批量大小
        这样可以减少空轮询带来的CPU浪费
